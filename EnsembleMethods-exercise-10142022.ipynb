{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods Exercise (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the file `planes.csv` from the data folder as a pandas dataframe called features. The dataset has information about different types of airplanes, including the number of tails, year of production, type, manufacturer, model, number of engines, seat, speed, and engine type. \n",
    "\n",
    "In this exercise, we are going to train a classifier to predict the engine type based on the provided information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3322 entries, 0 to 3321\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   tailnum       3322 non-null   object \n",
      " 1   year          3252 non-null   float64\n",
      " 2   type          3322 non-null   object \n",
      " 3   manufacturer  3322 non-null   object \n",
      " 4   model         3322 non-null   object \n",
      " 5   engines       3322 non-null   int64  \n",
      " 6   seats         3322 non-null   int64  \n",
      " 7   speed         23 non-null     float64\n",
      " 8   engine        3322 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 233.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tailnum</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>engines</th>\n",
       "      <th>seats</th>\n",
       "      <th>speed</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10156</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145XR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N102UW</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N103US</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N104UW</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10575</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145LR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tailnum    year                     type      manufacturer      model  \\\n",
       "0  N10156  2004.0  Fixed wing multi engine           EMBRAER  EMB-145XR   \n",
       "1  N102UW  1998.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "2  N103US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "3  N104UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "4  N10575  2002.0  Fixed wing multi engine           EMBRAER  EMB-145LR   \n",
       "\n",
       "   engines  seats  speed     engine  \n",
       "0        2     55    NaN  Turbo-fan  \n",
       "1        2    182    NaN  Turbo-fan  \n",
       "2        2    182    NaN  Turbo-fan  \n",
       "3        2    182    NaN  Turbo-fan  \n",
       "4        2     55    NaN  Turbo-fan  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "planes = pd.read_csv('data/planes.csv')\n",
    "planes.info()\n",
    "planes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a brief Exploratory Data Analysis. Display summary statistics, handle missing values (if the number of missing values is less than 100 remove those rows), if needed remove unnecessary columns, check the data distribution, and report if there are correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tailnum</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>engines</th>\n",
       "      <th>seats</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N10156</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145XR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N102UW</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N103US</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N104UW</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>AIRBUS INDUSTRIE</td>\n",
       "      <td>A320-214</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10575</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fixed wing multi engine</td>\n",
       "      <td>EMBRAER</td>\n",
       "      <td>EMB-145LR</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tailnum    year                     type      manufacturer      model  \\\n",
       "0  N10156  2004.0  Fixed wing multi engine           EMBRAER  EMB-145XR   \n",
       "1  N102UW  1998.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "2  N103US  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "3  N104UW  1999.0  Fixed wing multi engine  AIRBUS INDUSTRIE   A320-214   \n",
       "4  N10575  2002.0  Fixed wing multi engine           EMBRAER  EMB-145LR   \n",
       "\n",
       "   engines  seats     engine  \n",
       "0        2     55  Turbo-fan  \n",
       "1        2    182  Turbo-fan  \n",
       "2        2    182  Turbo-fan  \n",
       "3        2    182  Turbo-fan  \n",
       "4        2     55  Turbo-fan  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "planes.isnull().sum()\n",
    "planes.dropna(subset=['year'], axis=0, inplace=True)\n",
    "del  planes['speed']\n",
    "planes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "correlation = planes.corr()\n",
    "correlation\n",
    "sns.heatmap(correlation, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the categorical features in the dataset into ordinal features using the Ordinal Encoder, use ordinal encoding with the Label Encoder for the column `engine` as target labels, and normalize the data to the range [0,1]. Display the shape of the data and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tailnum</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>engines</th>\n",
       "      <th>seats</th>\n",
       "      <th>engine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>Turbo-fan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tailnum    year  type  manufacturer  model  engines  seats     engine\n",
       "0      0.0  2004.0   0.0          15.0  102.0        2     55  Turbo-fan\n",
       "1      1.0  1998.0   0.0           2.0   83.0        2    182  Turbo-fan\n",
       "2      2.0  1999.0   0.0           2.0   83.0        2    182  Turbo-fan\n",
       "3      3.0  1999.0   0.0           2.0   83.0        2    182  Turbo-fan\n",
       "4      4.0  2002.0   0.0          15.0  101.0        2     55  Turbo-fan"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categs_feats = planes[['tailnum', 'type','manufacturer','model']]\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "categs_encoded = encoder.fit_transform(categs_feats)\n",
    "planes[['tailnum', 'type','manufacturer','model']] = pd.DataFrame(categs_encoded, columns=categs_feats.columns, index=categs_feats.index)\n",
    "\n",
    "planes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2    2697\n",
       "3     526\n",
       "1      21\n",
       "5       5\n",
       "4       2\n",
       "0       1\n",
       "Name: engine, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "embtown_feat = planes[['engine']]\n",
    "label_encoder = LabelEncoder()\n",
    "embtown_encoded = label_encoder.fit_transform(embtown_feat)\n",
    "\n",
    "planes['engine'] = pd.DataFrame(embtown_encoded, columns=embtown_feat.columns, index=embtown_feat.index)\n",
    "\n",
    "\n",
    "planes['engine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2697\n",
       "3     526\n",
       "1      21\n",
       "5       5\n",
       "4       2\n",
       "Name: engine, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = planes[planes['engine'] == 0 ].index\n",
    "planes.drop(index, axis = 0, inplace=True)\n",
    "planes['engine'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 8.42105263e-01, 0.00000000e+00, 5.55555556e-01,\n",
       "        8.50000000e-01, 3.33333333e-01, 1.18303571e-01, 2.50000000e-01],\n",
       "       [3.07597662e-04, 7.36842105e-01, 0.00000000e+00, 7.40740741e-02,\n",
       "        6.91666667e-01, 3.33333333e-01, 4.01785714e-01, 2.50000000e-01],\n",
       "       [6.15195325e-04, 7.54385965e-01, 0.00000000e+00, 7.40740741e-02,\n",
       "        6.91666667e-01, 3.33333333e-01, 4.01785714e-01, 2.50000000e-01],\n",
       "       [9.22792987e-04, 7.54385965e-01, 0.00000000e+00, 7.40740741e-02,\n",
       "        6.91666667e-01, 3.33333333e-01, 4.01785714e-01, 2.50000000e-01],\n",
       "       [1.23039065e-03, 8.07017544e-01, 0.00000000e+00, 5.55555556e-01,\n",
       "        8.41666667e-01, 3.33333333e-01, 1.18303571e-01, 2.50000000e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = planes.drop('engine', axis=1)\n",
    "y = planes['engine']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(planes)\n",
    "\n",
    "planes_std = scaler.transform(planes)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "planes_std[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data inputs (2438, 7)\n",
      "Training labels (2438,)\n",
      "Testing data inputs (813, 7)\n",
      "Testing labels (813,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12, stratify=y)\n",
    "\n",
    "print('Training data inputs', X_train.shape)\n",
    "print('Training labels', y_train.shape)\n",
    "print('Testing data inputs', X_test.shape)\n",
    "print('Testing labels', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Ensemble\n",
    "\n",
    "Train a hard voting ensemble using k-Nearest Neighbors, SVM, and Logistic Regression, and **compare the accuracy of the ensemble to the individual classifiers**.\n",
    "\n",
    "You can use the default values for the models, you don't need to perform fine-tuning.\n",
    "\n",
    "Differently from the examples in the lecture notes on Ensemble Methods, use a 5-fold cross-validation. This means that you don't need to split the data into train and test sets, as this will be performed by the cross_validate function in scikit-learn. \n",
    "\n",
    "Report the mean and standard distribution of the accuracy scores for the 5-fold cross validation. \n",
    "\n",
    "***Use the same approach with 5-fold cross-validation for all models in this exercise***. \n",
    "\n",
    "You may get warnings for some of the models, so if you wish you can ignore the warnings with the following lines.\n",
    "\n",
    "```\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy of k-Nearest Neighbors is 97.05 %\n",
      "Logistic Regression accuracy is 82.16 %\n",
      "SVM accuracy is 85.36 %\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn import neighbors\n",
    "\n",
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "accuracy = knn_model.score(X_test, y_test)\n",
    "print('The test accuracy of k-Nearest Neighbors is {0:5.2f} %'.format(accuracy*100))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_preds = lr_model.predict(X_test)\n",
    "lr_acc = accuracy_score(y_test, lr_preds)\n",
    "print('Logistic Regression accuracy is {0:5.2f} %'.format(lr_acc*100))\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "poly_svm = SVC(kernel='poly')\n",
    "poly_svm.fit(X_train, y_train)\n",
    "polysvm_pred = poly_svm.predict(X_test)\n",
    "SVM_acc = accuracy_score(y_test, polysvm_pred)\n",
    "print('SVM accuracy is {0:5.2f} %'.format(SVM_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble accuracy is 87.2079 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    \n",
    "    estimators=[('log_reg', lr_model),\n",
    "                ('knn', knn_model),\n",
    "                ('svm', poly_svm)], \n",
    "    voting='hard')\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "voting_preds = voting_classifier.predict(X_test)\n",
    "voting_acc = accuracy_score(y_test, voting_preds)\n",
    "print('Voting Ensemble accuracy is {0:7.4f} %'.format(voting_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy of lr is: 0.820 +/- 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy of knn is: 0.974 +/- 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean cross-validation accuracy of SVM is: 0.857 +/- 0.010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "lr_model = LogisticRegression()\n",
    "cv_result = cross_validate(lr_model, X_train, y_train, cv=5)\n",
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy of lr is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "cv_result = cross_validate(knn_model, X_train, y_train, cv=5)\n",
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy of knn is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "poly_svm = SVC(kernel='poly')\n",
    "cv_result = cross_validate(poly_svm, X_train, y_train, cv=5)\n",
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy of SVM is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add SGD and Naive Bayes classifiers to the three models above, and report the results of the hard Voting Ensemble with the five individual models. Are there any improvements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SGD test accuracy is 83.27 %\n",
      "The  naive bayes test accuracy is 83.27 %\n",
      "Hard Voting Ensemble accuracy is 83.2718 %\n"
     ]
    }
   ],
   "source": [
    "# Your code here\\\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model_1 = SGDClassifier(max_iter=80, loss='hinge', random_state=1)\n",
    "\n",
    "sgd_model_1 .fit(X_train, y_train)\n",
    "\n",
    "sgd_pred = sgd_model_1 .predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, sgd_pred)\n",
    "print('The SGD test accuracy is {0:5.2f} %'.format(accuracy*100))\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model_1 = GaussianNB()\n",
    "\n",
    "nb_model_1.fit(X_train, y_train)\n",
    "\n",
    "nb_pred = nb_model_1.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, nb_pred)\n",
    "print('The  naive bayes test accuracy is {0:5.2f} %'.format(accuracy*100))\n",
    "\n",
    "\n",
    "voting_classifier = VotingClassifier(\n",
    "    \n",
    "    estimators=[('log_reg', lr_model),\n",
    "                ('knn', knn_model),\n",
    "                ('sgd',sgd_model_1),\n",
    "                ('nb', nb_model_1),\n",
    "                ('svm', poly_svm)], \n",
    "    voting='hard')\n",
    "\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "voting_preds = voting_classifier.predict(X_test)\n",
    "voting_acc = accuracy_score(y_test, voting_preds)\n",
    "print('Hard Voting Ensemble accuracy is {0:7.4f} %'.format(voting_acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a soft Voting Ensemble using 3 individual models of your choice, and compare the results to the hard Voting Ensemble model. Are the results as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Ensemble accuracy is 93.6039 %\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "knn_model = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "lr_model = LogisticRegression()\n",
    "poly_svm = SVC(kernel='poly', probability=True)\n",
    "\n",
    "voting_classifier_soft = VotingClassifier(\n",
    "    \n",
    "    estimators=[('log_reg', lr_model),\n",
    "                ('knn', knn_model),\n",
    "                ('svm', poly_svm)], \n",
    "     voting='soft')\n",
    "\n",
    "voting_classifier_soft.fit(X_train, y_train)\n",
    "voting_preds = voting_classifier_soft.predict(X_test)\n",
    "voting_acc = accuracy_score(y_test, voting_preds)\n",
    "print('Soft Voting Ensemble accuracy is {0:7.4f} %'.format(voting_acc*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Ensemble\n",
    "\n",
    "Train two Bagging Ensembles, one with bootstrapping and one with pasting, and compare the results. You can use the same hyperparameters as in the examples in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping Bagging Ensemble accuracy is 97.1710 %\n",
      "Pasting Bagging Ensemble accuracy is 98.6470 %\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_classifier = BaggingClassifier(\n",
    "      DecisionTreeClassifier(class_weight='balanced'),\n",
    "    max_samples=0.5, max_features=0.5, bootstrap=True)\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "bagging_preds = bagging_classifier.predict(X_test)\n",
    "bagging_acc = accuracy_score(y_test, bagging_preds)\n",
    "print('Bootstrapping Bagging Ensemble accuracy is {0:7.4f} %'.format(bagging_acc*100))\n",
    "\n",
    "bagging_classifier2 = BaggingClassifier(\n",
    "      DecisionTreeClassifier(class_weight='balanced'),\n",
    "    max_samples=0.5, max_features=0.5, bootstrap=False)\n",
    "bagging_classifier2.fit(X_train, y_train)\n",
    "bagging_preds = bagging_classifier2.predict(X_test)\n",
    "bagging_acc = accuracy_score(y_test, bagging_preds)\n",
    "print('Pasting Bagging Ensemble accuracy is {0:7.4f} %'.format(bagging_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a grid search for the better of these two ensembles, by using the following percentages of used data instances: 10%, 30%, 50%, 80%, and 100%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9872807755747803\n",
      "{'max_samples': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "bagging_classifier2 = BaggingClassifier(\n",
    "      DecisionTreeClassifier(class_weight='balanced'),\n",
    "    max_samples=0.5, max_features=0.5, bootstrap=False)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {'max_samples': [0.1, 0.3, 0.5, 0.8, 1.0]}\n",
    "\n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(bagging_classifier2, hyper_grid, scoring='accuracy')\n",
    "results = grid_search.fit(X_train, y_train)\n",
    "print(results.best_score_)\n",
    "print(results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Ensemble\n",
    "\n",
    "Train Boosting Ensembles using Gradient Boosting, AdaBoost, and XGBoost ensembles, and compare the results. Don't forget to use 5-fold cross-validation with all models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Ensemble accuracy is 97.4170 %\n",
      "AdaBoost Ensemble accuracy is 90.7749 %\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qz/bx_sydpd1ws4f5d4yyqbtwf00000gn/T/ipykernel_52897/1890171605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AdaBoost Ensemble accuracy is {0:7.4f} %'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madaboost_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mxgb_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grad_boost_classifier = GradientBoostingClassifier(\n",
    "                        n_estimators=500, \n",
    "                        learning_rate=0.8, \n",
    "                        random_state=42,\n",
    "                        max_depth=2)\n",
    "\n",
    "grad_boost_classifier.fit(X_train, y_train)\n",
    "gboost_preds = grad_boost_classifier.predict(X_test)\n",
    "gboost_acc = accuracy_score(y_test, gboost_preds)\n",
    "print('Gradient Boosting Ensemble accuracy is {0:7.4f} %'.format(gboost_acc*100))\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=3, class_weight='balanced'), \n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5)\n",
    "\n",
    "adaboost_classifier.fit(X_train, y_train)\n",
    "adaboost_preds = adaboost_classifier.predict(X_test)\n",
    "adaboost_acc = accuracy_score(y_test, adaboost_preds)\n",
    "print('AdaBoost Ensemble accuracy is {0:7.4f} %'.format(adaboost_acc*100))\n",
    "\n",
    "import xgboost as xgb\n",
    "#i dont know why no have model of xgboost\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xgboost_preds = xgb_classifier.predict(X_test)\n",
    "xgboost_acc = accuracy_score(y_test, xgboost_preds)\n",
    "print('XGBoost Ensemble accuracy is {0:7.4f} %'.format(xgboost_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_boost_classifier = GradientBoostingClassifier(\n",
    "                        n_estimators=500, \n",
    "                        learning_rate=0.8, \n",
    "                        random_state=42,\n",
    "                        max_depth=2)\n",
    "cv_result = cross_validate(grad_boost_classifier, X_train, y_train, cv=5)\n",
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy of grad_boost is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "adaboost_classifier = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=3, class_weight='balanced'), \n",
    "    n_estimators=300,\n",
    "    learning_rate=0.5)\n",
    "cv_result = cross_validate(adaboost_classifier, X_train, y_train, cv=5)\n",
    "scores = cv_result[\"test_score\"]\n",
    "print(\"The mean cross-validation accuracy of adaboost is: \"\n",
    "      f\"{scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking Ensemble\n",
    "\n",
    "Train a Stacking Ensemble with Random Forest and SVM Classifier as base estimators, and Logistic Regression as the final estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble accuracy is  0.6150 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py:153: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py:153: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "base_estimators = [\n",
    "    ('rand', RandomForestClassifier(random_state=42)),\n",
    "    ('svc', SVC(random_state=42))]\n",
    "\n",
    "final_estimator = LogisticRegression()\n",
    "\n",
    "stack_classifier = StackingClassifier(estimators = base_estimators, \n",
    "                               final_estimator = final_estimator)\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "stack_preds = stack_classifier.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, stack_preds)\n",
    "print('Stacking Ensemble accuracy is {0:7.4f} %'.format(stack_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train two other Stacking Ensembles using other classifiers of your choice as the final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble accuracy2 is 98.6470 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:1097: RuntimeWarning: Number of classes in training fold (4) does not match total number of classes (5). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  RuntimeWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble accuracy3 is  0.6150 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:87: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:192: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:160: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(arr, axis, dtype, out, keepdims)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:490: RuntimeWarning: invalid value encountered in true_divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/Users/jiangchang/opt/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:490: RuntimeWarning: overflow encountered in square\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "base_estimators = [\n",
    "    ('rand', RandomForestClassifier(random_state=42)),\n",
    "    ('svc', SVC(random_state=42))]\n",
    "\n",
    "final_estimator =  neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "stack_classifier = StackingClassifier(estimators = base_estimators, \n",
    "                               final_estimator = final_estimator)\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "stack_preds = stack_classifier.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, stack_preds)\n",
    "print('Stacking Ensemble accuracy2 is {0:7.4f} %'.format(stack_acc*100))\n",
    "\n",
    "base_estimators = [\n",
    "    ('rand', RandomForestClassifier(random_state=42)),\n",
    "    ('svc', SVC(random_state=42))]\n",
    "\n",
    "final_estimator =   GaussianNB()\n",
    "\n",
    "stack_classifier = StackingClassifier(estimators = base_estimators, \n",
    "                               final_estimator = final_estimator)\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "stack_preds = stack_classifier.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, stack_preds)\n",
    "print('Stacking Ensemble accuracy3 is {0:7.4f} %'.format(stack_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train another Stacking Ensemble with Random Forest and XGBoost as base estimators, and Logistic Regression as the final estimator, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qz/bx_sydpd1ws4f5d4yyqbtwf00000gn/T/ipykernel_52897/157754737.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m base_estimators = [\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'rand'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     ('xgb', xgb.XGBClassifier())]\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfinal_estimator\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "#still same problem\n",
    "base_estimators = [\n",
    "    ('rand', RandomForestClassifier(random_state=42)),\n",
    "    ('xgb', xgb.XGBClassifier())]\n",
    "\n",
    "final_estimator =  LogisticRegression()\n",
    "\n",
    "stack_classifier = StackingClassifier(estimators = base_estimators, \n",
    "                               final_estimator = final_estimator)\n",
    "\n",
    "stack_classifier.fit(X_train, y_train)\n",
    "stack_preds = stack_classifier.predict(X_test)\n",
    "stack_acc = accuracy_score(y_test, stack_preds)\n",
    "print('Stacking Ensemble accuracy2 is {0:7.4f} %'.format(stack_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
