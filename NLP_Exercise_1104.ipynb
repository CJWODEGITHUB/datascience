{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uY9v1Z0BwZ-"
   },
   "source": [
    "# Natural Language Processing Exercise (10 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ywvKQtxyolm"
   },
   "source": [
    "# 1. Load the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ppto8S84haTw"
   },
   "source": [
    "In this exercise we will use the Reuters newswire dataset, which consists of 11,228 newswires from Reuters, labeled in 46 topics. Each newswire is a text sequence that is encoded as a list of word indexes, i.e., each word is a token represented by an integer. Reuters newswire dataset is available in the Keras built-in datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2805,
     "status": "ok",
     "timestamp": 1667594108416,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 360
    },
    "id": "eTTzVWAukqPF",
    "outputId": "d96ec0d4-0c38-4466-fef2-3f950a6d47e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:2.5.0\n",
      "Keras version:2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Print the version of tf\n",
    "print(\"TensorFlow version:{}\".format(tf.__version__))\n",
    "print(\"Keras version:{}\".format(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrTHxGrpzOTK"
   },
   "source": [
    "We can load the `word_index` for the Reuters dataset, which is a dictionary consisting of words as keys and the corresponding integer indices as values. As we can see below, there are 30,979 words in the vocabulary for this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "XPFQvurEauLM"
   },
   "outputs": [],
   "source": [
    "word_index = keras.datasets.reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1667594108416,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 360
    },
    "id": "iNhJYXoEcXzW",
    "outputId": "201be9dd-e767-44f6-cd2c-2238fd7bd12b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30979"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1667594108417,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 360
    },
    "id": "-OQIzppdcOmY",
    "outputId": "89b186f5-3831-4590-ddd2-361b5d561ec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mdbl', 10996),\n",
       " ('fawc', 16260),\n",
       " ('degussa', 12089),\n",
       " ('woods', 8803),\n",
       " ('hanging', 13796),\n",
       " ('localized', 20672),\n",
       " ('sation', 20673),\n",
       " ('chanthaburi', 20675),\n",
       " ('refunding', 10997),\n",
       " ('hermann', 8804)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's print 10 words and indices from the vocabulary\n",
    "list(word_index.items())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eRfE58mz4zR"
   },
   "source": [
    "Let's load the dataset by using the first 30,000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Q3Zy-k25gU6"
   },
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.reuters.load_data(num_words=max_features, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht3sOllj0FpY"
   },
   "source": [
    "Print the length of train_data, train_labels, test_data, and test_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "Aoqianu15gZ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 8982 2246 2246\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "print(len(train_data), len(train_labels), len(test_data), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqUhSL1D0ejQ"
   },
   "source": [
    "Note again that each sequence in the dataset is a list of integer tokens representing words. \n",
    "Print the first and second sequences in the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "DWGv9ouYcm1P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 27595,\n",
       " 28842,\n",
       " 8,\n",
       " 43,\n",
       " 10,\n",
       " 447,\n",
       " 5,\n",
       " 25,\n",
       " 207,\n",
       " 270,\n",
       " 5,\n",
       " 3095,\n",
       " 111,\n",
       " 16,\n",
       " 369,\n",
       " 186,\n",
       " 90,\n",
       " 67,\n",
       " 7,\n",
       " 89,\n",
       " 5,\n",
       " 19,\n",
       " 102,\n",
       " 6,\n",
       " 19,\n",
       " 124,\n",
       " 15,\n",
       " 90,\n",
       " 67,\n",
       " 84,\n",
       " 22,\n",
       " 482,\n",
       " 26,\n",
       " 7,\n",
       " 48,\n",
       " 4,\n",
       " 49,\n",
       " 8,\n",
       " 864,\n",
       " 39,\n",
       " 209,\n",
       " 154,\n",
       " 6,\n",
       " 151,\n",
       " 6,\n",
       " 83,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 155,\n",
       " 11,\n",
       " 15,\n",
       " 7,\n",
       " 48,\n",
       " 9,\n",
       " 4579,\n",
       " 1005,\n",
       " 504,\n",
       " 6,\n",
       " 258,\n",
       " 6,\n",
       " 272,\n",
       " 11,\n",
       " 15,\n",
       " 22,\n",
       " 134,\n",
       " 44,\n",
       " 11,\n",
       " 15,\n",
       " 16,\n",
       " 8,\n",
       " 197,\n",
       " 1245,\n",
       " 90,\n",
       " 67,\n",
       " 52,\n",
       " 29,\n",
       " 209,\n",
       " 30,\n",
       " 32,\n",
       " 132,\n",
       " 6,\n",
       " 109,\n",
       " 15,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "RJQlhq_56RYo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3267,\n",
       " 699,\n",
       " 3434,\n",
       " 2295,\n",
       " 56,\n",
       " 16784,\n",
       " 7511,\n",
       " 9,\n",
       " 56,\n",
       " 3906,\n",
       " 1073,\n",
       " 81,\n",
       " 5,\n",
       " 1198,\n",
       " 57,\n",
       " 366,\n",
       " 737,\n",
       " 132,\n",
       " 20,\n",
       " 4093,\n",
       " 7,\n",
       " 19261,\n",
       " 49,\n",
       " 2295,\n",
       " 13415,\n",
       " 1037,\n",
       " 3267,\n",
       " 699,\n",
       " 3434,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 241,\n",
       " 16,\n",
       " 855,\n",
       " 129,\n",
       " 231,\n",
       " 783,\n",
       " 5,\n",
       " 4,\n",
       " 587,\n",
       " 2295,\n",
       " 13415,\n",
       " 2,\n",
       " 775,\n",
       " 7,\n",
       " 48,\n",
       " 34,\n",
       " 191,\n",
       " 44,\n",
       " 35,\n",
       " 1795,\n",
       " 505,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKHAeTGP2gUf"
   },
   "source": [
    "Based on the word_index, we can find the sentences that correspond to each sequence of integers, as in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1667594109093,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 360
    },
    "id": "zBbrkBYsgi4s",
    "outputId": "2b6e37c0-7909-4ec2-9e51-087aa7cd6b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 'mcgrath', 'rentcorp', 'said', 'as', 'a', 'result', 'of', 'its', 'december', 'acquisition', 'of', 'space', 'co', 'it', 'expects', 'earnings', 'per', 'share', 'in', '1987', 'of', '1', '15', 'to', '1', '30', 'dlrs', 'per', 'share', 'up', 'from', '70', 'cts', 'in', '1986', 'the', 'company', 'said', 'pretax', 'net', 'should', 'rise', 'to', 'nine', 'to', '10', 'mln', 'dlrs', 'from', 'six', 'mln', 'dlrs', 'in', '1986', 'and', 'rental', 'operation', 'revenues', 'to', '19', 'to', '22', 'mln', 'dlrs', 'from', '12', '5', 'mln', 'dlrs', 'it', 'said', 'cash', 'flow', 'per', 'share', 'this', 'year', 'should', 'be', '2', '50', 'to', 'three', 'dlrs', 'reuter', '3']\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value,key) for (key, value) in word_index.items()])\n",
    "\n",
    "print([reverse_word_index.get(i-3) for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuVQZivC4j0d"
   },
   "source": [
    "The labels are the categories of the newswires. All 46 categories are shown below.\n",
    "\n",
    "```\n",
    "Reuters dataset labels:\n",
    "{'copper': 6, 'livestock': 28, 'gold': 25, 'money-fx': 19, 'ipi': 30, 'trade': 11, 'cocoa': 0, 'iron-steel': 31, \n",
    "'reserves': 12, 'tin': 26, 'zinc': 37, 'jobs': 34, 'ship': 13, 'cotton': 14, 'alum': 23, 'strategic-metal': 27, \n",
    "'lead': 45, 'housing': 7, 'meal-feed': 22, 'gnp': 21, 'sugar': 10, 'rubber': 32, 'dlr': 40, 'veg-oil': 2, 'interest': 20,\n",
    " 'crude': 16, 'coffee': 9, 'wheat': 5, 'carcass': 15, 'lei': 35, 'gas': 41, 'nat-gas': 17, 'oilseed': 24, 'orange': 38,\n",
    "  'heat': 33, 'wpi': 43, 'silver': 42, 'cpi': 18, 'earn': 3, 'bop': 36, 'money-supply': 8, 'hog': 44, 'acq': 4,\n",
    "   'pet-chem': 39, 'grain': 1, 'retail': 29}\n",
    "```\n",
    "\n",
    "Printed below is the category for the first sentence, which corresponds to `earn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1667594109094,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 360
    },
    "id": "kyQp2RcO4ccw",
    "outputId": "d4bf415e-1009-4b9b-a768-1e5495b99f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1OQx2UA5_nd"
   },
   "source": [
    "Use Matplotlib to plot the histogram of the categories of newswires in train_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qTL9Xt6t7sCl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 46 artists>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARBUlEQVR4nO3df6zddX3H8efLFtRMN0DuGtZ2K9NupiazmgYx+gfTCAXMiokjkE07w1L/gAQTl6X4D/4YCyZT1ERJqjTWxVkbf4xGyViHJM4/BIoiUhjhihDaFHq1+CtmLGXv/XE+DWfl9t7b29Nzb+/n+UhOzvf7/n6+3/P5fnLP63z7/X7PaaoKSVIfXrLQHZAkjY+hL0kdMfQlqSOGviR1xNCXpI4sX+gOzOTcc8+tNWvWLHQ3JOm0cv/99/+sqiamW7aoQ3/NmjXs3bt3obshSaeVJE8eb5mndySpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOL+hu5i82ard9+Ue2Jmy9fgJ5I0vx4pC9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6MmvoJ3lZknuT/CjJviQfafXzk9yTZDLJV5Oc2eovbfOTbfmaoW3d0OqPJrnklO2VJGlacznSfw54W1W9HlgPbExyIfBx4Jaqeg3wLHBNa38N8Gyr39LakWQdcBXwOmAj8Lkky0a4L5KkWcwa+jXwmzZ7RnsU8Dbga62+A7iiTW9q87Tlb0+SVt9ZVc9V1U+BSeCCUeyEJGlu5nROP8myJA8Ah4A9wE+AX1TVkdZkP7CyTa8EngJoy38JvGq4Ps06w6+1JcneJHunpqZOeIckScc3p9Cvqueraj2wisHR+WtPVYeqaltVbaiqDRMT0/5n7pKkeTqhu3eq6hfA3cCbgbOSHP3tnlXAgTZ9AFgN0Jb/HvDz4fo060iSxmAud+9MJDmrTb8ceAfwCIPwf3drthm4vU3vbvO05d+pqmr1q9rdPecDa4F7R7QfkqQ5mMuvbJ4H7Gh32rwE2FVV30ryMLAzyT8APwRua+1vA/45ySRwmMEdO1TVviS7gIeBI8C1VfX8aHdHkjSTWUO/qh4E3jBN/XGmufumqv4b+MvjbOsm4KYT76YkaRT8Rq4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjs4Z+ktVJ7k7ycJJ9Sa5v9Q8nOZDkgfa4bGidG5JMJnk0ySVD9Y2tNplk66nZJUnS8SyfQ5sjwAer6gdJXgncn2RPW3ZLVf3TcOMk64CrgNcBfwD8R5I/aYs/C7wD2A/cl2R3VT08ih2RJM1u1tCvqoPAwTb96ySPACtnWGUTsLOqngN+mmQSuKAtm6yqxwGS7GxtDX1JGpMTOqefZA3wBuCeVrouyYNJtic5u9VWAk8Nrba/1Y5XP/Y1tiTZm2Tv1NTUiXRPkjSLOYd+klcAXwc+UFW/Am4FXg2sZ/AvgU+MokNVta2qNlTVhomJiVFsUpLUzOWcPknOYBD4X66qbwBU1TNDyz8PfKvNHgBWD62+qtWYoS5JGoO53L0T4Dbgkar65FD9vKFm7wIeatO7gauSvDTJ+cBa4F7gPmBtkvOTnMngYu/u0eyGJGku5nKk/xbgPcCPkzzQah8Crk6yHijgCeD9AFW1L8kuBhdojwDXVtXzAEmuA+4ElgHbq2rfyPZEkjSrudy98z0g0yy6Y4Z1bgJumqZ+x0zrSZJOLb+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sisoZ9kdZK7kzycZF+S61v9nCR7kjzWns9u9ST5TJLJJA8meePQtja39o8l2XzqdkuSNJ25HOkfAT5YVeuAC4Frk6wDtgJ3VdVa4K42D3ApsLY9tgC3wuBDArgReBNwAXDj0Q8KSdJ4zBr6VXWwqn7Qpn8NPAKsBDYBO1qzHcAVbXoT8KUa+D5wVpLzgEuAPVV1uKqeBfYAG0e5M5KkmZ3QOf0ka4A3APcAK6rqYFv0NLCiTa8EnhpabX+rHa9+7GtsSbI3yd6pqakT6Z4kaRZzDv0krwC+Dnygqn41vKyqCqhRdKiqtlXVhqraMDExMYpNSpKaOYV+kjMYBP6Xq+obrfxMO21Dez7U6geA1UOrr2q149UlSWOyfLYGSQLcBjxSVZ8cWrQb2Azc3J5vH6pfl2Qng4u2v6yqg0nuBP5x6OLtxcANo9mNhbVm67enrT9x8+Vj7okkzWzW0AfeArwH+HGSB1rtQwzCfleSa4AngSvbsjuAy4BJ4LfA+wCq6nCSjwH3tXYfrarDo9gJSdLczBr6VfU9IMdZ/PZp2hdw7XG2tR3YfiIdlCSNjt/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjs4Z+ku1JDiV5aKj24SQHkjzQHpcNLbshyWSSR5NcMlTf2GqTSbaOflckSbOZy5H+F4GN09Rvqar17XEHQJJ1wFXA69o6n0uyLMky4LPApcA64OrWVpI0Rstna1BV302yZo7b2wTsrKrngJ8mmQQuaMsmq+pxgCQ7W9uHT7zLkqT5Oplz+tclebCd/jm71VYCTw212d9qx6u/SJItSfYm2Ts1NXUS3ZMkHWu+oX8r8GpgPXAQ+MSoOlRV26pqQ1VtmJiYGNVmJUnM4fTOdKrqmaPTST4PfKvNHgBWDzVd1WrMUJckjcm8jvSTnDc0+y7g6J09u4Grkrw0yfnAWuBe4D5gbZLzk5zJ4GLv7vl3W5I0H7Me6Sf5CnARcG6S/cCNwEVJ1gMFPAG8H6Cq9iXZxeAC7RHg2qp6vm3nOuBOYBmwvar2jXpnJEkzm8vdO1dPU75thvY3ATdNU78DuOOEeidJGim/kStJHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerIrKGfZHuSQ0keGqqdk2RPksfa89mtniSfSTKZ5MEkbxxaZ3Nr/1iSzadmdyRJM5nLkf4XgY3H1LYCd1XVWuCuNg9wKbC2PbYAt8LgQwK4EXgTcAFw49EPCknS+Mwa+lX1XeDwMeVNwI42vQO4Yqj+pRr4PnBWkvOAS4A9VXW4qp4F9vDiDxJJ0ik233P6K6rqYJt+GljRplcCTw21299qx6u/SJItSfYm2Ts1NTXP7kmSpnPSF3KrqoAaQV+Obm9bVW2oqg0TExOj2qwkifmH/jPttA3t+VCrHwBWD7Vb1WrHq0uSxmi+ob8bOHoHzmbg9qH6e9tdPBcCv2ynge4ELk5ydruAe3GrSZLGaPlsDZJ8BbgIODfJfgZ34dwM7EpyDfAkcGVrfgdwGTAJ/BZ4H0BVHU7yMeC+1u6jVXXsxWFJ0ik2a+hX1dXHWfT2adoWcO1xtrMd2H5CvZMkjZTfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk+cmsnOQJ4NfA88CRqtqQ5Bzgq8Aa4Angyqp6NkmATwOXAb8F/qaqfnAyry9NZ83Wb7+o9sTNly9AT6TFZxRH+n9eVeurakOb3wrcVVVrgbvaPMClwNr22ALcOoLXliSdgFNxemcTsKNN7wCuGKp/qQa+D5yV5LxT8PqSpOM42dAv4N+T3J9kS6utqKqDbfppYEWbXgk8NbTu/lb7f5JsSbI3yd6pqamT7J4kadhJndMH3lpVB5L8PrAnyX8NL6yqSlInssGq2gZsA9iwYcMJrStJmtlJHelX1YH2fAj4JnAB8MzR0zbt+VBrfgBYPbT6qlaTJI3JvEM/ye8keeXRaeBi4CFgN7C5NdsM3N6mdwPvzcCFwC+HTgNJksbgZE7vrAC+ObgTk+XAv1TVvyW5D9iV5BrgSeDK1v4OBrdrTjK4ZfN9J/HaJ2W6W/rA2/oWirdYSuMz79CvqseB109T/znw9mnqBVw739eTJJ08v5ErSR052bt3dJrz1IrUF4/0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiPfpqyt+L0G980hfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcRbNnXCvO1ROn15pC9JHfFI/zTjUbakk2Hod8APCklHGfpLxHTBDob7XDl+6oWhL42Z//LSQjL0j+Eb8vTgkbk0P0s69A1wLRT/9rRYjT30k2wEPg0sA75QVTePuw+LxWIOhsVyJL2YxwgWR//m04eZ1hn1Po26f6O0WP7Ox2msoZ9kGfBZ4B3AfuC+JLur6uFx9kOnzvHerD2+uU7UYh+jxd6/mYzrg+d0GKNxH+lfAExW1eMASXYCm4AlG/pL9Q+nJ0vpaH4u683HOPu3GA4sFvu/rmaSqjolG572xZJ3Axur6m/b/HuAN1XVdUNttgBb2uyfAo+O4KXPBX42gu0sBY7FgOPwAsdiYCmNwx9V1cR0Cxbdhdyq2gZsG+U2k+ytqg2j3ObpyrEYcBxe4FgM9DIO4/7tnQPA6qH5Va0mSRqDcYf+fcDaJOcnORO4Ctg95j5IUrfGenqnqo4kuQ64k8Etm9urat8YXnqkp4tOc47FgOPwAsdioItxGOuFXEnSwvL39CWpI4a+JHVkyYd+ko1JHk0ymWTrQvdnnJJsT3IoyUNDtXOS7EnyWHs+eyH7OA5JVie5O8nDSfYlub7VuxqLJC9Lcm+SH7Vx+Eirn5/knvYe+Wq7yWLJS7IsyQ+TfKvNdzEOSzr0h3724VJgHXB1knUL26ux+iKw8ZjaVuCuqloL3NXml7ojwAerah1wIXBt+zvobSyeA95WVa8H1gMbk1wIfBy4papeAzwLXLNwXRyr64FHhua7GIclHfoM/exDVf0PcPRnH7pQVd8FDh9T3gTsaNM7gCvG2aeFUFUHq+oHbfrXDN7oK+lsLGrgN232jPYo4G3A11p9yY8DQJJVwOXAF9p86GQclnrorwSeGprf32o9W1FVB9v008CKhezMuCVZA7wBuIcOx6Kd0ngAOATsAX4C/KKqjrQmvbxHPgX8PfC/bf5VdDIOSz30NYMa3K/bzT27SV4BfB34QFX9anhZL2NRVc9X1XoG34a/AHjtwvZo/JK8EzhUVfcvdF8WwqL77Z0R82cfXuyZJOdV1cEk5zE44lvykpzBIPC/XFXfaOUuxwKgqn6R5G7gzcBZSZa3o9we3iNvAf4iyWXAy4DfZfB/fHQxDkv9SN+ffXix3cDmNr0ZuH0B+zIW7XztbcAjVfXJoUVdjUWSiSRntemXM/h/LR4B7gbe3Zot+XGoqhuqalVVrWGQCd+pqr+ik3FY8t/IbZ/mn+KFn324aWF7ND5JvgJcxOAnY58BbgT+FdgF/CHwJHBlVR17sXdJSfJW4D+BH/PCOdwPMTiv381YJPkzBhcolzE44NtVVR9N8scMbnI4B/gh8NdV9dzC9XR8klwE/F1VvbOXcVjyoS9JesFSP70jSRpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SO/B/q8ib+yW2dSAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "from matplotlib import pyplot as plt\n",
    "newswires = {'copper': 6, 'livestock': 28, 'gold': 25, 'money-fx': 19, 'ipi': 30, 'trade': 11, 'cocoa': 0, 'iron-steel': 31, \n",
    "'reserves': 12, 'tin': 26, 'zinc': 37, 'jobs': 34, 'ship': 13, 'cotton': 14, 'alum': 23, 'strategic-metal': 27, \n",
    "'lead': 45, 'housing': 7, 'meal-feed': 22, 'gnp': 21, 'sugar': 10, 'rubber': 32, 'dlr': 40, 'veg-oil': 2, 'interest': 20,\n",
    " 'crude': 16, 'coffee': 9, 'wheat': 5, 'carcass': 15, 'lei': 35, 'gas': 41, 'nat-gas': 17, 'oilseed': 24, 'orange': 38,\n",
    "  'heat': 33, 'wpi': 43, 'silver': 42, 'cpi': 18, 'earn': 3, 'bop': 36, 'money-supply': 8, 'hog': 44, 'acq': 4,\n",
    "   'pet-chem': 39, 'grain': 1, 'retail': 29}\n",
    "newswires = {v:k for k,v in newswires.items()}\n",
    "labels, nums = [], []\n",
    "for k,v in newswires.items():\n",
    "    labels.append(k)\n",
    "    nums.append(0)\n",
    "for i in train_labels:\n",
    "    if i in labels:\n",
    "        nums[labels.index(i)] += 1\n",
    "plt.bar(labels, nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEr062hB5Guz"
   },
   "source": [
    "## 2. Pad the Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxLLnwKzcs-f"
   },
   "source": [
    "Create a new NumPy array called `len_sequences` which has the same length as the train_data array. Write a for-loop and assign the length of each sequence (number of tokens in each sequence) to the elements in `len_sequences`.\n",
    "\n",
    "Afterward, use the `len_sequences` array to print the average length of train sequences, the length of the longest train sequence, and the length of the shortest train sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "QHDIzN1P6f6H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.5398574927633 2376 13\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "l = [len(x) for x in train_data]\n",
    "n = np.asarray(l)\n",
    "print(np.mean(n), max(n), min(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG3bi_Y06dDN"
   },
   "source": [
    "Create a new integer variable `pad_length` which is approximately equal to 2 x the average length of train sequences. E.g., if the average is 48.1, set maxlen to 100, or something in that range.\n",
    "\n",
    "Apply padding to the train and test sequences, so that they have length equal to `pad_length`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "YQDKR4dR6df3"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "train_data = pad_sequences(train_data, maxlen=300)\n",
    "test_data = pad_sequences(test_data, maxlen=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-nU3ol8fDH9"
   },
   "source": [
    "Display the first 2 padded sequences in the train dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "79YQGT8F7SKu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     1 27595 28842\n",
      "     8    43    10   447     5    25   207   270     5  3095   111    16\n",
      "   369   186    90    67     7    89     5    19   102     6    19   124\n",
      "    15    90    67    84    22   482    26     7    48     4    49     8\n",
      "   864    39   209   154     6   151     6    83    11    15    22   155\n",
      "    11    15     7    48     9  4579  1005   504     6   258     6   272\n",
      "    11    15    22   134    44    11    15    16     8   197  1245    90\n",
      "    67    52    29   209    30    32   132     6   109    15    17    12]\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     1  3267   699  3434  2295    56 16784  7511\n",
      "     9    56  3906  1073    81     5  1198    57   366   737   132    20\n",
      "  4093     7 19261    49  2295 13415  1037  3267   699  3434     8     7\n",
      "    10   241    16   855   129   231   783     5     4   587  2295 13415\n",
      "     2   775     7    48    34   191    44    35  1795   505    17    12]\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "print(train_data[0])\n",
    "print(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgA536U1ob1b"
   },
   "source": [
    "## 3. Create and Train a Model with Dense Layers\n",
    "\n",
    "Define a Keras model `model_1` similar to the model in Lecture 18, which has an Embedding, Flatten, Dense, Dropout, and a final Dense layer. Use 64-dimensional vectors as outputs of the Embedding Layer, and 1,024 neurons in the first Dense layer. Make sure that the last layer outputs 46 categories, and recall that with multiclass datasets the activation of the last layer should be `softmax`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "xJiIJ4yl7Zxc"
   },
   "outputs": [],
   "source": [
    "# Your Code Here\n",
    "model_1 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.Flatten(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCkSj_0u8Bhb"
   },
   "source": [
    "Display the summary of the model, and report the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "oMGDwp5BZtoe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 300, 64)           1920000   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 19200)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              19661824  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 46)                47150     \n",
      "=================================================================\n",
      "Total params: 21,628,974\n",
      "Trainable params: 21,628,974\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YOU0KrI9CH5"
   },
   "source": [
    "Compile the model with Adam optimizer using the default settings. If needed, review Lecture 16 to ensure that you apply the correct loss function. \n",
    "\n",
    "Afterward, train the model for 5 epochs, and ensure that there are no errors in fitting the model. Use a batch size of 128, and split the training data so that 20% is used for validation.\n",
    "\n",
    "Evaluate the model on the test dataset. The expected accuracy should be between 65% and 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "p5fpNW8m7mKS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 2s 21ms/step - loss: 2.1395 - accuracy: 0.4571 - val_loss: 1.6658 - val_accuracy: 0.5671\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 1s 19ms/step - loss: 1.2581 - accuracy: 0.7051 - val_loss: 1.3839 - val_accuracy: 0.6750\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.6600 - accuracy: 0.8548 - val_loss: 1.3054 - val_accuracy: 0.6984\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.3342 - accuracy: 0.9357 - val_loss: 1.3542 - val_accuracy: 0.6973\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 0.2023 - accuracy: 0.9585 - val_loss: 1.3826 - val_accuracy: 0.7045\n",
      "71/71 - 0s - loss: 1.3544 - accuracy: 0.6937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6936776638031006"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "model_1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_1.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=5, batch_size=128)\n",
    "test_loss, test_acc = model_1.evaluate(test_data,  test_labels, verbose=2)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K584uIcRDCBN"
   },
   "source": [
    "### Apply Early Stopping\n",
    "\n",
    "Create a model named `model_2` that is similar to `model_1`, but it uses Early Stopping callback. See Lectures 16 and 21 for examples with Early Stopping callback. \n",
    "\n",
    "Train the model, plot the learning curves, and report the accuracy on the test dataset. \n",
    "\n",
    "The training time should be just a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "k5uZqsT9_WX6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 2s 21ms/step - loss: 2.1197 - accuracy: 0.4605 - val_loss: 1.6817 - val_accuracy: 0.5665\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 1.2291 - accuracy: 0.7091 - val_loss: 1.3715 - val_accuracy: 0.6767\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.6313 - accuracy: 0.8639 - val_loss: 1.3249 - val_accuracy: 0.7012\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.3060 - accuracy: 0.9418 - val_loss: 1.3426 - val_accuracy: 0.7045\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1923 - accuracy: 0.9609 - val_loss: 1.3366 - val_accuracy: 0.7112\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1667 - accuracy: 0.9614 - val_loss: 1.4203 - val_accuracy: 0.6912\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1486 - accuracy: 0.9638 - val_loss: 1.3493 - val_accuracy: 0.7123\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1340 - accuracy: 0.9635 - val_loss: 1.3683 - val_accuracy: 0.7134\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1423 - accuracy: 0.9634 - val_loss: 1.3903 - val_accuracy: 0.6956\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1191 - accuracy: 0.9640 - val_loss: 1.4072 - val_accuracy: 0.6967\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1182 - accuracy: 0.9656 - val_loss: 1.3533 - val_accuracy: 0.7106\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1080 - accuracy: 0.9666 - val_loss: 1.3657 - val_accuracy: 0.7023\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.1096 - accuracy: 0.9652 - val_loss: 1.3748 - val_accuracy: 0.7034\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAF3CAYAAACMpnxXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA7iElEQVR4nO3dd3xcZ533/e9vZtTbyJJc1NydxCW2EsekOlnCbgqQkA0tu5SEQJbdhYUbHhZY9qbfsAvPs3CzmwUChCS7lIQsCQFSICS2U5ziuDe5yEWSi4qtYqtrruePGTmyYtkjW0dnyuf9euk1c84cSV8Zc+Xro2uuy5xzAgAAABCfgN8BAAAAgGRCgQYAAADGgAINAAAAjAEFGgAAABgDCjQAAAAwBhRoAAAAYAw8K9Bmdq+ZNZnZ5lFeNzP7npntMrONZnaRV1kAAGfGuA0A8fHyDvR9kq4/zes3SJob+7hL0vc9zAIAOLP7xLgNAGfkWYF2zq2SdOQ0l9ws6QEX9ZKksJlN8yoPAOD0GLcBID5+zoGukFQ/7Lghdg4AkJgYtwFAUsjvAPEws7sU/XWh8vLyLj7//PN9TgQAY/faa6+1OOfK/M7htWQfsxuOdquzp18XTCv0OwoAn402bvtZoBslVQ07roydewPn3D2S7pGkpUuXujVr1nifDgDGmZnt8zvDOYpr3E72Mfu7T+/Qd5/eqRe+fr2yQkG/4wDw0Wjjtp9TOB6T9IHYu7ovldTunDvoYx4AwOmlxbhdHs6RJB1u7/U5CYBE5dkdaDP7haRrJJWaWYOkL0nKkCTn3A8kPS7pRkm7JHVJusOrLACAM2PcjqqIFeiGti5Vl+T6nAZAIvKsQDvnbjvD607S33v1/QEAY8O4HTVUoA+09ficBECiYidCAACGmVqULUk60NbtcxIAiYoCDQDAMNkZQZXmZ1GgAYyKAg0AwAgV4Ww1UqABjIICDQDACBXFORRoAKNKio1UAKQf55wiThqMuOiHcxocjD4ORCKKRKSBSOT112PXDAw6RVz0OBQIKBQ0ZQRt2POAQgFTKBg4cT4jaDIzv39kJJDyohw9s71Jzjn+bgB4Awo00kb/YES9AxH19A+eeBz+vHcgov6BiCTJzGSSzIY+ho6HnZfFHiWNODYb/jx6wYlrY6/HPi12HHuMnRn53+vhxyOvGXqMRKSIc3Iu+hiJFdChIjp07vXXh653Jz73VNdHnFP/oFP/YPTPp3/QqW8wov7BiPoGoo8nzo08HvoYOPm4b9jXiUScBiLuxOOge70QT6RgwBQKxAr2sGI9VLozYgU8FAwoI2D6h2vnavm8lN9UMG2Vh3PU0x/R0a5+TcrL9DsOgARDgca4Gow4bWps156WY6codMMKmxtZ2Ia/LkUio18/cIoifKIQD0TUGzvujR0PvT7RhSwdDBXOjKApMxRUZtCUEQrEzgWix7HnhZkZJx0PfV4oaAqaKRgIKBjQyY8WfT1g0XIbCJz8GP28Ua4x00DEaWAwov7Y48CgU38k9jgYef31wehd7ej56PP+waHXRn5+9HkwwF3JVDa0mUrj0W4KNIA3oEDjnO1v7dJzu5r1/M4Wvbi7Ve3d/eP69c2kgJkCsTvBQTNlZwSUnRFUVij2GHtelJOhrIIsZWcElR0KKCsjoOxQ8OTHjOCJ51nDXsvOiJY6SXJOcnKxx9fvyuqkc9Hzbtj1Gv7aiM8/Ud/d0IM78b1Oehy6LHZieO13I77I8M8Z+jMKmCkQiP5ZDT/3+p/j63+WgWHnbNjnnnxNdApE5lDpDUWLb0YgoAAlEimqsjhWoNu6taiyyOc0ABINBRpj1t7Vrxd3t+i5XS16fmeL9h/pkiSVF2XrugVTdOXcMi0oL1RGIBAtZYGzKHHDrmf+IYCJVn5iMxXeSAjgjSjQOKO+gYjW7j+q53dGS/OmhjZFnJSfFdKls0p055UzdeXcUs0qzaPsAkgJxbkZys4IsBIHgFOiQOMNnHPa2XRMz+1s0fM7m/XyniPq6htUMGBaXFmkj715rq6aW6olVeETUx4AIJWYmSrCOdyBBnBKFGhIkpo6e/TCrhY9t7NFL+xq0eGOXknSzNI83XpRpa6cW6rLZpeoMDvD56QAMDHKKdAARkGBTlO9A4N6qe6Int/ZrOd2tmj7oU5J0V9bXj6nVFfNKdWVc0tVWZzrc1IA8EdFOEfbDnb6HQNAAqJAp6HjvQP66x+/rPX1bcoMBrR0RrH+8frzdNWc6Jv/WFkBAKJ3oFuO9aqnf1DZGUG/4wBIIBToNNM3ENHf/mytNja06VvvvFBvv7BcOZn8hwEARqqIrcRxsL1HM0vzfE4DIJHwDrA0Eok4/ePDG7RqR7O+ccsivXtpFeUZAEbBUnYARkOBThPOOf2fx7fp0fUH9JnrztN7l1X7HQkAEtrQHWiWsgMwEgU6Tdyzqk4/eX6Pbr98hv7umtl+xwGAhDe1KFtm0e28AWA4CnQaePi1Bn3zie1664XT9MW3zWezEwCIQ2YooMkFWUzhAPAGFOgU98z2w/rs/2zUFXNK9G/vXswKGwAwBuXhHB1op0ADOBkFOoW9tu+o/u5na3XBtAL98P1LlRXiDYMAMBbl4RymcAB4Awp0itp5uFMfuu9VTS3M1n13LFN+FisWAsBYVYRzdKC9R5GI8zsKgARCgU5BB9q69YF7X1FGMKAHPvQmleZn+R0JAJJSRThHfQMRtR7v8zsKgARCgU4xbV19+uC9r6izZ0D3f+gSVZewFTcAnC3WggZwKhToFNLdN6g771+jfa1duucDF2tBeZHfkQAgqZWHsyWxFjSAkzExNkX0D0b09z9fq7X7j+ruv7pIl88u9TsSACS9ynD0t3jcgQYwHHegU4BzTp//9SY9s71JX7t5oW5cNM3vSACQEgpzQsrLDHIHGsBJKNAp4FtP1erh1xr0iWvn6n2XTvc7DgCkDDOLrgVNgQYwDAU6yf3k+T36/ord+qs3VeuTb5nrdxwASDnl4RzuQAM4CQU6if1mfaO+9rutun7BVH3t5oVs0Q0AHqgoztGBth6/YwBIIBToJLVqR7M+/dAGvWnmJH33vUsUZItuAPBERThHR473qbtv0O8oABIEBToJbahv00f/+zXNnVKgH31wqbIz2KIbALzCUnYARqJAJ5m65mO6475XNSkvU/ffcYkKszP8jgQAKa28iM1UAJyMAp1EDnf06P0/eUUm6b/ufJMmF2b7HQkAUl5FMQUawMnYSCVJtHf364P3vqKjXX365V2XamZpnt+RACAtTCnMVsAo0ABexx3oJNDTP6iP3L9Gu5uP6Yfvv1gXVob9jgQAaSMjGNCUwmw1UKABxHAHOsENRpz+4Rfr9MreI/rebTW6am6Z35EAIO1UsJkKgGG4A53AnHP650c36w9bD+tLb5+vmxaX+x0JANJSdDdC1oIGEEWBTmDfX7lbv3hlv/7umtm644qZfscBgLRVHs7RwfZuRSLO7ygAEgAFOkG1d/XrP57Zpb+YP0Wfue48v+MAQFqrCGerf9Cp+Viv31EAJAAKdIL675f3qatvUJ98yzy26AYAnw0tZcdmKgAkCnRC6h0Y1H0v7tVVc0s1v7zQ7zgAkPbKw6wFDeB1FOgE9Oi6RjV39uqu5bP8jgIA0OsFuvEoBRoABTrhRCJO96yq0/xphbpyTqnfcQAAkgqzM1SQFeIONABJFOiE88z2Ju1uPq67ls9i7jMAJJCK4hw1spQdAFGgE849z9WpvChbb71wmt9RAADDlLOZCoAYCnQCWV/fplf2HNGHrpypjCD/0wBAIikPZ7MKBwBJFOiEcs+q3SrIDum9y6r9jgIAGKE8nKP27n4d6x3wOwoAn1GgE8S+1uN6cvMhve/S6crPCvkdBwAwQkVsJY6D3IUG0h4FOkH8+Lk9CgUCuuPyGX5HAQCcwlCBZhoHAAp0AjhyvE+/eq1e76gp1+TCbL/jAABOoZwCDSCGAp0AHli9Vz39ETZOAYAENqUwW8GAsRIHAAq037r7BvXA6n269vzJmjO5wO84AIBRBAOmqYXZOsBa0EDao0D77OG1DTpyvI+7zwCQBCrCOWznDYAC7afBiNOPn6vT4qqwls2c5HccAMAZsBY0AIkC7as/bDmkfa1d+hu27QaApFBRnKNDHT0ajDi/owDwkacF2syuN7NaM9tlZp87xevVZvasma0zs41mdqOXeRKJc04/XFWn6SW5um7BVL/jAABjdhzKwzkajDg1dTIPGkhnnhVoMwtKulvSDZLmS7rNzOaPuOyfJT3knKuR9F5J/+lVnkTz6t6jWl/fpg9fOVPBAHefAfiLMTs+J5ayYx40kNa8vAO9TNIu51ydc65P0i8l3TziGiepMPa8SNIBD/MklHtW7dakvEy98+Iqv6MAgMSYHRc2UwEgeVugKyTVDztuiJ0b7suS3mdmDZIel/RxD/MkjF1NnXp6W5Pef+l05WQG/Y4DABJjdlyG7kCzlB2Q3vx+E+Ftku5zzlVKulHSf5nZGzKZ2V1mtsbM1jQ3N094yPH2o1V7lBUK6AOXTfc7CgCMRVqO2cPlZ4VUlJPBZipAmvOyQDdKGj4/oTJ2brg7JT0kSc651ZKyJZWO/ELOuXucc0udc0vLyso8ijsxmjp79Mi6Rr3z4kqV5Gf5HQcAhjBmx6k8nMMUDiDNeVmgX5U018xmmlmmom84eWzENfslXStJZnaBooNxat2uGOH+F/eqPxLRh69i4xQACYUxO04V4WzuQANpzrMC7ZwbkPQxSU9J2qboO7e3mNlXzeym2GWflvQRM9sg6ReSbnfOpezimsd7B/TfL+3XdfOnamZpnt9xAOAExuz4VXAHGkh7IS+/uHPucUXfaDL83BeHPd8q6QovMySSB1+tV3t3v+66mrvPABIPY3Z8ysM56uwZUEdPvwqzM/yOA8AHfr+JMG0MDEb0k+f36JIZxbqoutjvOACAs/T6ShzchQbSFQV6gvx+00E1tnXrruWz/Y4CADgHFcUUaCDdUaAngHNO96yq0+yyPF17/mS/4wAAzsHrm6mwFjSQrijQE+DF3a3acqBDH7lqlgJs2w0ASa0sP0sZQWM7byCNUaAnwA9X1ak0P0vvqBm5qRcAINkEAqapRSxlB6QzCrTHth3s0KodzbrjihnKzmDbbgBIBRXhHAo0kMYo0B770ao65WYG9b43sW03AKSKcgo0kNYo0B460NatxzYc0HsuqVJRLmuFAkCqqAjn6FBHj/oHI35HAeADCrSHfvrCHjlJd1450+8oAIBxVB7OUcRJhztYiQNIRxRoj3T09OsXr9TrrYumqbI41+84AIBxVHFiMxUKNJCOKNAe+fnL+3Wsd0B3LWfbbgBINeUn1oLu8jkJAD9QoD3QNxDRT1/YoyvmlGhhRZHfcQAA46w8nC2JO9BAuqJAe+CxDQd0uKOXbbsBIEXlZoY0KS9TjazEAaQlCvQ4c87pR6vqdP7UAi2fW+p3HACAR8rDbKYCpCsK9DhbsaNZtYc7ddfyWTJj224ASFXlRTls5w2kKQr0OLtnZZ2mFmbrbReW+x0FAOChoc1UnHN+RwEwwSjQ42hTQ7tW17XqQ1fOUGaIP1oASGWVxTk63jeoju4Bv6MAmGC0vHH0w1W7VZAV0m3Lqv2OAgDw2OtL2TGNA0g3FOhxUn+kS49vOqi/elO1CrLZthsAUh0FGkhfFOhx8pPn9ygYMN1xBdt2A0A6eH0taAo0kG4o0OPg6PE+PfhqvW5aXKGpRdl+xwEATIDSvCxlhgIUaCANUaDHwX+/tE/d/YNs2w0AaSQQMJUXZauBAg2kHQr0OerpH9T9q/fqmvPKdN7UAr/jAAAm0NBSdgDSCwX6HP16baNajvVx9xkA0hAFGkhPFOhz9LOX92lhRaEum1XidxQAwASrCOeoqbNXfQMRv6MAmEAU6HNwuKNHWw506K2Lytm2GwDSUEU4R85Jh9p7/I4CYAJRoM/Byh3NkqRrzivzOQkAwA+sBQ2kJwr0OVhZ26wphVk6nzcPAkBaqiiOFmjmQQPphQJ9lgYGI3puZ7OunlfG9A0ASFPTithMBUhHFOiztK6+TR09A7rmvMl+RwEA+CQ7I6jS/EymcABphgJ9llbUNikYMF0xp9TvKAAAH5WHcyjQQJqhQJ+llTuadXF1sYpyMvyOAgDwUQVrQQNphwJ9Fpo6e7S5sUNXs/oGAKS9oTvQzjm/owCYIBTos7BqR4sk6ep5FGgASHfl4Rz19Ed0tKvf7ygAJggF+iysqG1SWUGWFpQX+h0FAOCzijArcQDphgI9RtHl61pYvg4AIEmqCOdKYjMVIJ1QoMdoQ0O72rv72X0QACBJKo/dgW48SoEG0gUFeoxW1jYpYNJVcyjQAABpUl6msjMCTOEA0ggFeoxW7GhWTXWxinJZvg4AIJmZysM5OtBOgQbSBQV6DFqO9WpjQ7uuYfUNAMAwFeEcNbb1+B0DwAShQI/Bqh3NksT23QCAk5QX5TAHGkgjFOgxWLmjWaX5mSxfBwA4SXk4Ry3HetXTP+h3FAATgAIdp8GI06odzVo+r0yBAMvXAQBeV1GcI0k61M40DiAdUKDjtLGhTUe7+tl9EADwBuVspgKkFQp0nFbUNitg0vK5FGgAwMkqwtE70A0UaCAtUKDjtGJHsxZXhVWcl+l3FABAgplaxB1oIJ1QoONw5HifNja06Zp5rL4BAHijrFBQkwuyKNBAmqBAx+G5nc1yTmzfDQAYVXk4R40UaCAtUKDjsKK2WZPyMrWoosjvKACABFURztEBNlMB0gIF+gwiQ8vXzS1l+ToAwKjKw9lqbOtWJOL8jgLAYxToM9jU2K7W433sPggAOK25UwrUNxBRXcsxv6MA8BgF+gxW7miWmbSc9Z8BAKdRUxWWJK3b3+ZrDgDeo0CfwYraJl1YGdYklq8DAJzG7LJ8FWSFtK6+ze8oADxGgT6Ntq4+ra9vY/dBAMAZBQKmJdVh7kADaYACfRqrdrYowvJ1AIA4LakKq/ZQh7r6BvyOAsBDFOjTWFHbpOLcDC2uDPsdBQCQBGqqw4o4aWNDu99RAHiIAj2KoeXrrppbpiDL1wEA4rCkqlgSbyQEUp2nBdrMrjezWjPbZWafG+Wad5vZVjPbYmY/9zLPWGw92KGWY31M3wCQNpJ5zE4Uk/IyNb0kV+vrj/odBYCHQl59YTMLSrpb0p9LapD0qpk95pzbOuyauZI+L+kK59xRM0uYxZZX1DZJkq6aS4EGkPqSfcxOJDVVYb24u1XOOZnxG0wgFXl5B3qZpF3OuTrnXJ+kX0q6ecQ1H5F0t3PuqCQ555o8zDMmK2qbtaiiSGUFWX5HAYCJkNRjdiKpqS5WU2evDrazrTeQqrws0BWS6ocdN8TODTdP0jwze8HMXjKz60/1hczsLjNbY2ZrmpubPYr7uvaufq3df5TpGwDSSdKO2YlmCRuqACnP7zcRhiTNlXSNpNsk/cjMwiMvcs7d45xb6pxbWlbmfal9blczy9cBwBsl5JidaC6YVqjMUEDr9jMPGkhVXhboRklVw44rY+eGa5D0mHOu3zm3R9IORQdnX62sbVZRDsvXAUgrSTtmJ5rMUEALywu1nh0JgZTlZYF+VdJcM5tpZpmS3ivpsRHXPKronQyZWamivx6s8zDTGTnntHJHs66cW6pQ0O8b9AAwYZJyzE5UNdXF2tTYrr6BiN9RAHjAs4bonBuQ9DFJT0naJukh59wWM/uqmd0Uu+wpSa1mtlXSs5I+45xr9SpTPLYe7FBTZ6+uYftuAGkkWcfsRFVTHVbvQETbD3X4HQWABzxbxk6SnHOPS3p8xLkvDnvuJH0q9pEQVtRG3/ByNfOfAaSZZByzE9XQGwnX17fpQqYDAimHOQojrKxt1oLyQk0uyPY7CgAgSVWEc1RWkMVKHECKokAP09HTr9dYvg4AcI7MTDVVYVbiAFIUBXqYF3a2aDDidPU8NtcCAJybJdVh7W3t0tHjfX5HATDOKNDDrKhtVkF2SBdVh/2OAgBIcjVVxZLEcnZACqJAxwwtX3cVy9cBAMbBhZVFCpiYxgGkIJpizPZDnTrU0aNrmL4BABgHeVkhzZtSoHXcgQZSzhkLtJm93cxSvmiv3MHydQCA8VVTXaz19W2KRJzfUQCMo3iK8Xsk7TSzb5nZ+V4H8suK2iadP7VAUwpZvg4AMD5qqsPq7BlQXctxv6MAGEdnLNDOufdJqpG0W9J9ZrbazO4yswLP002Qzp5+rdl7VNecx/QNAMD4qYltqMI8aCC1xDU1wznXIelhSb+UNE3SLZLWmtnHPcw2YV7Y1aqBiGP9ZwDAuJpdlq+CrBDzoIEUE88c6JvM7BFJKyRlSFrmnLtB0mJJn/Y23sRYuaNJBVkhXTy92O8oAIAUEgiYllSHtZ4dCYGUEs8d6Fslfcc5t8g5923nXJMkOee6JN3paboJ4JzTytpmXTGnVBksXwcAGGdLqsLafqhDXX0DfkcBME7iaYxflvTK0IGZ5ZjZDElyzv3Jm1gTZ2fTMR1o72H6BgDAEzXVYUWctLGh3e8oAMZJPAX6V5Iiw44HY+dSworaJkksXwcA8MYSdiQEUk48BTrknOsbOog9z/Qu0sRaUdus86YUaFpRjt9RAAApaFJepqaX5LISB5BC4inQzWZ209CBmd0sqcW7SBPnWO+AXt17hOkbAABP1VSFtW5/m5xjQxUgFcRToD8q6Z/MbL+Z1Uv6rKS/8TbWxFi9u1X9g47pGwAATy2pCqups1cH23v8jgJgHITOdIFzbrekS80sP3Z8zPNUE2RFbZPyMoNaOn2S31EAACmspjo6D3rd/jaVh5kyCCS7MxZoSTKzt0paICnbzCRJzrmvepjLc845raht1uVzSpUZYvk6AKnDzPIkdTvnImY2T9L5kp5wzvX7HC1tXTCtUJmhgNbXH9VbL5zmdxwA5yiejVR+IOk9kj4uySS9S9J0j3N5bnfzMTW2dTP/GUAqWqXoDY8KSX+Q9H5J9/maKM1lhgJaWF6odWyoAqSEeG69Xu6c+4Cko865r0i6TNI8b2N5b0VtsyTpmvMm+5wEAMadxTa7+ktJ/+mce5eiv0WEj2qqi7WpsV39g5EzXwwgocVToIfe8dBlZuWS+iUl/e+fVu5o1tzJ+apgLhqA1GNmdpmkv5b0+9i5oI95oOiGKr0DEW0/2Ol3FADnKJ4C/VszC0v6tqS1kvZK+rmHmTzX1Tegl+tYvg5AyvqkpM9LesQ5t8XMZkl61t9IWFIVliStq2c9aCDZnfZNhGYWkPQn51ybpP8xs99JynbOJfV+pKt3t6pvMKKr5zF9A0Dqcc6tlLRSOjGOtzjn/sHfVKgI56isIEvr9rfpA5f5nQbAuTjtHWjnXETS3cOOe5O9PEvR+c+5mUFdMrPY7ygAMO7M7OdmVhhbjWOzpK1m9hm/c6U7M1NNVZgtvYEUEM8Ujj+Z2a02tH5dknPOacWOJl0+u0RZIaYEAkhJ851zHZLeIekJSTMVXYkDPltSHdaeluM6erzP7ygAzkE8BfpvJP1KUq+ZdZhZp5l1eJzLM3tajqv+SLeuZvUNAKkrw8wyFC3Qj8XWf2YP6QRQUxX9zSd3oYHkdsYC7ZwrcM4FnHOZzrnC2HHhRITzwonl6+bxBkIAKeuHir7hO0/SKjObLilpb3ykkgsrixQwaR0FGkhqZ9yJ0MyWn+q8c27V+Mfx3oodzZpVlqeqSbl+RwEATzjnvifpe8NO7TOzP/MrD16XlxXSvCkFWreflTiAZBbPVt7D33iSLWmZpNckvdmTRB7q7hvUS3Wtet+bkn4jRQAYlZkVSfqSpKEbICslfVVS0r8JPBXUVBfrdxsPKBJxCgRS4u1FQNqJZwrH24d9/LmkhZKS8p/OL9W1qm8gwvrPAFLdvZI6Jb079tEh6ae+JsIJNdVhdfYMqK7luN9RAJyleO5Aj9Qg6YLxDjIRVu5oVk5GUMtmTvI7CgB4abZz7tZhx18xs/V+hcHJaoY2VNl/VHMm5/sbBsBZiWcO9L/r9XdvByQtUXRHwqSzorZJl80uUXYGy9cBSGndZnalc+55STKzKyR1+5wJMbPL8lWQFdL6+ja9a2mV33EAnIV47kCvGfZ8QNIvnHMveJTHM3tbjmtva5fuuGKm31EAwGsflfRAbC60FJ1290Ef82CYQMC0pDqsdfvb/I4C4CzFU6AfltTjnBuUJDMLmlmuc67L22jja0VtkyQx/xlAynPObZC02MwKY8cdZvZJSRt9DYYTllSFdfezu9TVN6DczLOZTQnAT3HtRCgpZ9hxjqSnvYnjnRU7mjWzNE/TS/L8jgIAE8I51xHbkVCSPuVrGJykpjqsiJM2NbAwCpCM4inQ2c65Y0MHsedJtYhyT390+bqr2TwFQPpivbQEsrgyLIkNVYBkFU+BPm5mFw0dmNnFSrI3o7y854h6+lm+DkBaYyvvBFKSn6XpJblsqAIkqXgmXn1S0q/M7ICidzCmSnqPl6HG24raJmWFArp0VonfUQDAM2bWqVMXZdPJU/GQAGqqwnpxd6ucczLjFwRAMjljgXbOvWpm50s6L3aq1jnX722s8bWytlmXzmL5OgCpzTlX4HcGxG9JVViPrj+gg+09Kg/z7xsgmcSzDvTfS/qZc25z7LjYzG5zzv2n5+nGgXNO/+eWRcoI8q97AEDiqKkuliSt299GgQaSTDxzoD/inGsbOnDOHZX0Ec8SjTMz02WzS7R0BrsPAgASxwXTCpUZCmh9PfOggWQTT4EO2rDJWWYWlJTpXSQAAFJfZiigheWFbKgCJKF4CvSTkh40s2vN7FpJv5D0hLexAABIfTXVxdrU2K7+wYjfUQCMQTwF+rOSnlF0a9iPStok3s0NAMA5q6kOq3cgou0HO/2OAmAMzlignXMRSS9L2itpmaQ3S9rmbSwAAFLfkqqwJGkd86CBpDJqgTazeWb2JTPbLunfJe2XJOfcnznn/mOiAgIAkKoqwjkqK8jSeuZBA0nldMvYbZf0nKS3Oed2SZKZ/a8JSQUAQBowM9VUhdnSG0gyp5vC8ZeSDkp61sx+FHsDIYspAwAwjpZUh7Wn5biOHu/zOwqAOI1aoJ1zjzrn3ivpfEnPKrql92Qz+76Z/cUE5QMAIKXVVEU3VFnf0OZvEABxi+dNhMedcz93zr1dUqWkdYquzAEAAM7RhZVFCphYDxpIIvEsY3eCc+6oc+4e59y1XgUCACCd5GWFNG9KgdbtZyUOIFmMqUADAIDxV1NdrA31bYpEnN9RAMSBAg0AgM9qqsPq6BlQXctxv6MAiAMFGgAAn9UMbajCNA4gKVCgAQDw2eyyfBVkhbSe9aCBpOBpgTaz682s1sx2mdnnTnPdrWbmzGypl3kAAKNjzPZPIGBaXBVmJQ4gSXhWoM0sKOluSTdImi/pNjObf4rrCiR9QtLLXmUBAJweY7b/aqrD2n6oQ119A35HAXAGXt6BXiZpl3OuzjnXJ+mXkm4+xXVfk/Svkno8zAIAOD3GbJ/VVIcVcdKmhna/owA4Ay8LdIWk+mHHDbFzJ5jZRZKqnHO/P90XMrO7zGyNma1pbm4e/6QAAMZsny2uDEuS1jEPGkh4vr2J0MwCkv5N0qfPdG1s85alzrmlZWVl3ocDAJyEMdt7JflZml6Sq/XMgwYSnpcFulFS1bDjyti5IQWSFkpaYWZ7JV0q6THelAIAvmDMTgA1VWGt3X9UzrGhCpDIvCzQr0qaa2YzzSxT0nslPTb0onOu3TlX6pyb4ZybIeklSTc559Z4mAkAcGqM2QlgSVVYTZ29OtjOFHMgkXlWoJ1zA5I+JukpSdskPeSc22JmXzWzm7z6vgCAsWPMTgw11cWSxHrQQIILefnFnXOPS3p8xLkvjnLtNV5mAQCcHmO2/y6YVqjMUEDr9h/VjYum+R0HwCjYiRAAgASRGQpoYXkhG6oACY4CDQBAAqmpLtamxnb1D0b8jgJgFBRoAAASSE11WL0DEW0/2Ol3FACjoEADAJBAllSFJUnr6o/6GwTAqCjQAAAkkIpwjsoKsthQBUhgFGgAABKImammKsyW3kACo0ADAJBgllSHtafluI4e7/M7CoBToEADAJBgaqpiG6o0tPkbBMApUaABAEgwF1YWKWBiPWggQVGgAQBIMHlZIc2bUsCW3kCCokADAJCAaqqLtX7/UUUizu8oAEagQAMAkIBqqsLq6BlQXctxv6MAGIECDQBAAqqpDksS0ziABESBBgAgAc0uy1dBVkjr9rMjIZBoKNAAACSgQMC0uCrMShxAAqJAAwCQoGqqw6o93KmuvgG/owAYhgINAECCqqkOazDitKmh3e8oAIahQAMAkKAWV4YlSet4IyGQUCjQAAAkqJL8LE0vydV65kEDCYUCDQBAAqupCmtdPStxAImEAg0AQAJbUhXW4Y5eHWzv9jsKgBgKNAAACaymuliSWM4OSCAUaAAAEtgF0wqVGQqwoQqQQCjQAAAksMxQQAvLC9nSG0ggFGgAABJcTXWxNja0q7tv0O8oAESBBgAg4d24aKp6ByL63jM7/Y4CQBRoAAAS3sXTJ+mdF1fqR6vqVHuo0+84QNqjQAMAkAT+6cYLVJAd0hce2aRIxPkdB0hrFGgAAJLApLxMff7GC7Rm31E9tKbe7zhAWqNAAwCQJN51caWWzZykbz6xXS3Hev2OA6QtCjQAAEnCzPSNWxaqq29A3/j9Nr/jAGmLAg0AQBKZM7lAf7N8tn69rlEv7mrxOw6QlijQAAAkmY+9eY6ml+Tqnx/drN4B1oYGJhoFGgCAJJOdEdTXbl6oupbj+v6K3X7HAdIOBRoAgCS0fF6Z3r64XP/57G7VNR/zOw6QVijQAAAkqf/9tguUlRHQPz+6Wc6xNjQwUSjQAAAkqckF2frH68/Xi7tb9ej6Rr/jAGmDAg0AQBL762XVWlIV1td/t01tXX1+xwHSAgUaAIAkFgiYvvmXi9TW3a9/fXK733GAtECBBgAgyV0wrVB3XjlTv3ilXmv2HvE7DpDyKNAAAKSAT75lrirCOfrCI5vVPxjxOw6Q0ijQAACkgNzMkL5y0wLVHu7Uj56r8zsOkNIo0AAApIi3zJ+i6xZM0ff+tFP1R7r8jgOkLAo0AAAp5Ms3LVDQTP/7N6wNDXiFAg0AQAqZVpSjT/3FeVpR26zHNx3yOw6QkijQAACkmA9eNl0Lygv1ld9uUUdPv99xgJRDgQYAIMWEggF945ZFaj7Wq//vqVq/4wAphwINAEAKWlwV1gcuna4HXtqnDfVtfscBUgoFGgCAFPXp685TWX6W/umRTRpgbWhg3FCgAQBIUYXZGfrS2xdoy4EO3b96n99xgJRBgQYAIIXduGiqrjmvTP/2h1odbO/2Ow6QEijQAACkMDPT125eqEHn9OXHtvgdB0gJFGgAAFJc1aRc/cO1c/XUlsN6euthv+MASY8CDQBAGvjIVbM0b0q+vvTYFnX1DfgdB0hqFGgAANJARmxt6Ma2bn336Z1+xwGSGgUaAIA0sXTGJN22rEo/eX6Pth7o8DsOkLQ8LdBmdr2Z1ZrZLjP73Cle/5SZbTWzjWb2JzOb7mUeAMDoGLPTw2evP1/hnAx94dFNikSc33GApORZgTazoKS7Jd0gab6k28xs/ojL1kla6py7UNLDkr7lVR4AwOgYs9NHODdT//y2C7Ruf5t+/sp+v+MAScnLO9DLJO1yztU55/ok/VLSzcMvcM4965zrih2+JKnSwzwAgNExZqeRdyyp0BVzSvSvT25XU2eP33GApONlga6QVD/suCF2bjR3SnrCwzwAgNExZqeRobWhe/sj+trvtvkdB0g6CfEmQjN7n6Slkr49yut3mdkaM1vT3Nw8seEAACdhzE4Ns8ry9Xd/Nlu/3XBAq3bwvxMwFl4W6EZJVcOOK2PnTmJmb5H0BUk3Oed6T/WFnHP3OOeWOueWlpWVeRIWANIcY3Ya+ttrZmtWaZ7+6ZFNenrrYfUNRPyOBCQFLwv0q5LmmtlMM8uU9F5Jjw2/wMxqJP1Q0YG4ycMsAIDTY8xOQ1mhoL71zgvV3TeoDz+wRm/6xtP64m82a+3+o3KOFTqA0YS8+sLOuQEz+5ikpyQFJd3rnNtiZl+VtMY595iiv/7Ll/QrM5Ok/c65m7zKBAA4Ncbs9LV0xiS99E/X6rmdzfr12kY9+Gq9Hli9TzNKcvWOmgq9Y0mFZpTm+R0TSCiWbP/CXLp0qVuzZo3fMQBgzMzsNefcUr9zTCTG7OTT2dOvJzcf0iPrGrW6rlXOSRdVh3VLTYXedmG5ivMy/Y4ITJjRxm3P7kADAIDkU5CdoXctrdK7llbpYHu3frP+gB5Z26j//Zst+spvt+qa8ybrLy+q0JvPn6zsjKDfcQFfUKABAMApTSvK0Uevnq2PXj1bWw906NH1jfrN+kY9ve2wCrJDunHhNN1yUYWWzZikQMD8jgtMGAo0AAA4o/nlhZpfXqjPXn++Vu9u1SPrGvW7jQf04Jp6VYRzdPOSct1SU6G5Uwr8jgp4jgINAADiFgyYrpxbqivnlupr71igP249rEfWNeqHq+r0nyt2a0F5oW6pqdBNi8s1uTDb77iAJyjQAADgrORmhnTzkgrdvKRCzZ29+u2GA3p0faO+/vtt+sbj23TFnFK9Y0mFls8rU1lBlt9xgXFDgQYAAOesrCBLH7pypj505UztajqmR9c16pF1jfr0rzZIkuZNyddls0p02exSXTprksK5rOaB5EWBBgAA42rO5Hz9P9edp0/9+TxtamzXi7tb9eLuFj20pkH3r94nM2n+tEJdPrtEl88u1SUzJyk/i0qC5MHfVgAA4IlAwLS4KqzFVWH97TWz1TcQ0YaGNr24q1Wr61p0/4v79KPn9igYMF1YWXSiUF88vZgl8pDQKNAAAGBCZIYCumTGJF0yY5I+obnq6R/Ua/uO6sXdLVq9u1U/WFmnu5/drcxgQDXVYV0+u1SXzynR4sqwMkMBv+MDJ1CgAQCAL7IzgrpiTqmumFMqSTrWO6BX9xzR6rrolI/v/mmHvvO0lJMR1NIZxbp8dqkum12iheWFCgUp1PAPBRoAACSE/KyQ/uz8yfqz8ydLktq6+vTyniNaHZtD/a9PbpckFWSF9KZZk3TprBLVVIe1oLyIKR+YUBRoAACQkMK5mbpuwVRdt2CqJKm5s1cv1bXqxd2tWr27RU9va5IUXZt63pQCLa4s0oWVYV1YWaTzphYog7vU8AgFGgAAJIWygiy9fXG53r64XJJ0uKNHG+rbtLGhXRsa2vTklkP65av1kqLzredPK9TiyiItqgxrcWWRZpXlK+jTluN9AxEd7uhRY1u3Wo71qqa6WBXhHF+y4NxRoAEAQFKaUpitv1gwVX8Ru0PtnFP9kW5taGjTxoY2bWho169eiy6dJ0l5mUEtrCjS4qqwFlUUaXFlWFWTcmR2bqXaOaf27n41tnXrQFuPDrR160BbtxpijwfautXU2SvnTv68xVVh3bhwqm5YOE3VJbnnlAETiwINAABSgpmpuiRX1SW5J+5SD0ac6pqPaUNDuzY2RO9W3/fiXvUNRCRJxbkZJ+5QD03/mDJiC/Khu8cNR18vxAfau9U4rCx39Q2e9DmZwYDKw9kqD+foqrllKg/nqCKcrYpwrgpzQnphV6ue2HxQ33xiu775xHYtrCjUDQun6cZF0zSzNG9i/sBw1syN/OdQglu6dKlbs2aN3zEAYMzM7DXn3FK/c0wkxmwkor6BiHYc7ozeqa5v18bGdu043KnBSLQTTSnM0vlTC9XR0z/q3ePS/EyVh3NUXpQTfQxnqyI89DxHJXmZCsQxXaT+SJee2HxQj286pPX1bZKkC6YVRu9ML5qmOZPzx/vHxxiMNm5ToAFgglCggcTV3TeorQfbtaG+XZsa21V7qFPFeRkqL8pRRXFO7A5y9HFaUbYnq340tnXryc2H9MSmg1qz76ik6BboQ3em503JP+fpJhgbCjQA+IwCDSBeh9p79OTmg3p88yG9uveInJNml+XpxkXTdMPCabpgWgFlegKMNm4zBxoAACDBTC3K1u1XzNTtV8xUU2ePntpyWE9sOqi7n92lf39ml2aU5OqGRdN048JpWlhRSJmeYBRoAACABDa5IFvvv3S63n/pdLUe69Ufth7W45sO6p5Vdfr+it2qmpSjGxdO0w2LpmlxZRFlegJQoAEAAJJESX6WbltWrduWVevo8T79cethPb75oO59YY9+uKpO04qyNaUwW8GAKWgWfQyYAgFT0KKbzgRs+Dk7cS40dC4gBW3E64Ho61MKszWzNE8zSvM0rTA7rjdKpiIKNAAAQBIqzsvUuy+p0rsvqVJ7V7+e3nZYz2xvUkdPvyLOaTAS/egbjGgw4k46NxhxGnROkROP0SX/BoZdN/Ta0OcORNxJq5FkhQKaXpKrGSV5J0r10PMphVkpfSecAg0AAJDkinIzdOvFlbr14krPvkck4nSoo0d7W45rT+vx6GNLl+pajmtFbbP6BiMnrs3JCGp6Se6JYj2zJFawS3NVlp/85ZoCDQAAgDMKBOzEOteXzyk96bXBiNOBtm7tHVas97YeV+2hTv1x62ENRF6/dZ2fFYreuR5WrGeW5iorFFT/YET9gy72GMfzgdhxxJ143jfoNDDiuqvmlen9l04ftz8LCjQAAADOSTBgqpqUq6pJubpqbtlJrw0MRtTY1q09LdFyvbe1S3tajmtzY7ue3HzoxAY25yIzGFAoaMoIBpQRDCgzaMoIBRQKRM91dPef8/cYjgINAAAAz4SCAU0vydP0kjzpvJNf6xuIqOFol/a1dqlvMKLMWAHOCJpCwUD0OBQrxoFhz2PXZASjJXmip4RQoAEAAOCLzFBAs8ryNassubYsD/gdAAAAAEgmFGgAAABgDCjQAAAAwBhQoAEAAIAxoEADAAAAY0CBBgAAAMaAAg0AAACMAQUaAAAAGAMKNAAAADAGFGgAAABgDNjKGwAAAGfU39+vhoYG9fT0+B1l3GVnZ6uyslIZGRlxXU+BBgAAwBk1NDSooKBAM2bMkJn5HWfcOOfU2tqqhoYGzZw5M67PYQoHAAAAzqinp0clJSUpVZ4lycxUUlIypjvrFGgAAADEJdXK85Cx/lwUaAAAACSF/Px8vyNIokADAAAAY0KBBgAAQFJxzukzn/mMFi5cqEWLFunBBx+UJB08eFDLly/XkiVLtHDhQj333HMaHBzU7bfffuLa73znO+f8/VmFAwAAAGPyld9u0dYDHeP6NeeXF+pLb18Q17W//vWvtX79em3YsEEtLS265JJLtHz5cv385z/Xddddpy984QsaHBxUV1eX1q9fr8bGRm3evFmS1NbWds5ZuQMNAACApPL888/rtttuUzAY1JQpU3T11Vfr1Vdf1SWXXKKf/vSn+vKXv6xNmzapoKBAs2bNUl1dnT7+8Y/rySefVGFh4Tl/f+5AAwAAYEzivVM80ZYvX65Vq1bp97//vW6//XZ96lOf0gc+8AFt2LBBTz31lH7wgx/ooYce0r333ntO34c70AAAAEgqV111lR588EENDg6qublZq1at0rJly7Rv3z5NmTJFH/nIR/ThD39Ya9euVUtLiyKRiG699VZ9/etf19q1a8/5+3MHGgAAAEnllltu0erVq7V48WKZmb71rW9p6tSpuv/++/Xtb39bGRkZys/P1wMPPKDGxkbdcccdikQikqRvfvOb5/z9zTl3zl9kIi1dutStWbPG7xgAMGZm9ppzbqnfOSYSYzaQOrZt26YLLrjA7xieOdXPN9q4zRQOAAAAYAwo0AAAAMAYUKABAACAMaBAAwAAIC7J9t65eI3156JAAwAA4Iyys7PV2tqaciXaOafW1lZlZ2fH/TksYwcAAIAzqqysVENDg5qbm/2OMu6ys7NVWVkZ9/WeFmgzu17S/5UUlPRj59y/jHg9S9IDki6W1CrpPc65vV5mAgCcGmM2gNPJyMjQzJkz/Y6REDybwmFmQUl3S7pB0nxJt5nZ/BGX3SnpqHNujqTvSPpXr/IAAEbHmA0A8fNyDvQySbucc3XOuT5Jv5R084hrbpZ0f+z5w5KuNTPzMBMA4NQYswEgTl4W6ApJ9cOOG2LnTnmNc25AUrukEg8zAQBOjTEbAOKUFG8iNLO7JN0VOzxmZrVn8WVKJbWMX6oJQ+6JRe6Jlay5pbPLPt2LIImGMZvcEyhZc0vJmz3dcp9y3PayQDdKqhp2XBk7d6prGswsJKlI0TemnMQ5d4+ke84ljJmtOdVe5omO3BOL3BMrWXNLyZ19FIzZ44DcEytZc0vJm53cUV5O4XhV0lwzm2lmmZLeK+mxEdc8JumDsefvlPSMS7XFBQEgOTBmA0CcPLsD7ZwbMLOPSXpK0SWR7nXObTGzr0pa45x7TNJPJP2Xme2SdETRARsAMMEYswEgfp7OgXbOPS7p8RHnvjjseY+kd3mZYZhz+nWij8g9scg9sZI1t5Tc2U+JMXtckHtiJWtuKXmzk1uS8ds3AAAAIH5ezoEGAAAAUk7KF2gzu97Mas1sl5l9zu888TKzKjN71sy2mtkWM/uE35niZWZBM1tnZr/zO8tYmFnYzB42s+1mts3MLvM7UzzM7H/F/o5sNrNfmFm235lOxczuNbMmM9s87NwkM/ujme2MPRb7mfFURsn97djfk41m9oiZhX2MmHKScdxO5jFbSs5xmzHbe4zbo0vpAh3n1rSJakDSp51z8yVdKunvkyj7JyRt8zvEWfi/kp50zp0vabGS4GcwswpJ/yBpqXNuoaJv/krUN3bdJ+n6Eec+J+lPzrm5kv4UO0409+mNuf8oaaFz7kJJOyR9fqJDpaokHreTecyWknPcZsz23n1i3D6llC7Qim9r2oTknDvonFsbe96p6MAwclewhGNmlZLeKunHfmcZCzMrkrRc0VUG5Jzrc861+RoqfiFJObF1eXMlHfA5zyk551YpunLDcMO3hr5f0jsmMlM8TpXbOfeH2E58kvSSomsmY3wk5bidrGO2lJzjNmP2xGDcHl2qF+h4tqZNeGY2Q1KNpJd9jhKP70r6R0kRn3OM1UxJzZJ+Gvs15o/NLM/vUGfinGuU9P9K2i/poKR259wf/E01JlOccwdjzw9JmuJnmLP0IUlP+B0ihST9uJ1kY7aUnOM2Y7Z/GLeV+gU66ZlZvqT/kfRJ51yH33lOx8zeJqnJOfea31nOQkjSRZK+75yrkXRciflrqZPE5p7drOh/TMol5ZnZ+/xNdXZiG3Ik1bJAZvYFRX91/zO/syAxJNOYLSX1uM2YnQDSedxO9QIdz9a0CcvMMhQdiH/mnPu133nicIWkm8xsr6K/dn2zmf23v5Hi1iCpwTk3dMfoYUUH50T3Fkl7nHPNzrl+Sb+WdLnPmcbisJlNk6TYY5PPeeJmZrdLepukv2Y3vnGVtON2Eo7ZUvKO24zZ/mHcVuoX6Hi2pk1IZmaKzu3a5pz7N7/zxMM593nnXKVzboaif9bPOOeS4l/WzrlDkurN7LzYqWslbfUxUrz2S7rUzHJjf2euVRK8kWaY4VtDf1DSb3zMEjczu17RX3nf5Jzr8jtPiknKcTsZx2wpecdtxmxfMW4rxQt0bLL40Na02yQ95Jzb4m+quF0h6f2K3g1YH/u40e9QKe7jkn5mZhslLZH0DX/jnFns7svDktZK2qTo/6cTcpcoM/uFpNWSzjOzBjO7U9K/SPpzM9up6J2Zf/Ez46mMkvs/JBVI+mPs/5s/8DVkCknicZsxe+IxZnuMcfs034PfPAIAAADxS+k70AAAAMB4o0ADAAAAY0CBBgAAAMaAAg0AAACMAQUaAAAAGAMKNFKSmQ0OW0pqvZmN2w5VZjbDzDaP19cDgHTHmI1kE/I7AOCRbufcEr9DAADiwpiNpMIdaKQVM9trZt8ys01m9oqZzYmdn2Fmz5jZRjP7k5lVx85PMbNHzGxD7GNoy9Wgmf3IzLaY2R/MLMe3HwoAUhRjNhIVBRqpKmfErwPfM+y1dufcIkV3Jfpu7Ny/S7rfOXehpJ9J+l7s/PckrXTOLZZ0kaShHdHmSrrbObdAUpukWz39aQAgtTFmI6mwEyFSkpkdc87ln+L8Xklvds7VmVmGpEPOuRIza5E0zTnXHzt/0DlXambNkiqdc73DvsYMSX90zs2NHX9WUoZz7usT8KMBQMphzEay4Q400pEb5flY9A57PijeTwAAXmHMRsKhQCMdvWfY4+rY8xclvTf2/K8lPRd7/idJfytJZhY0s6KJCgkAkMSYjQTEv8CQqnLMbP2w4yedc0PLIhWb2UZF70jcFjv3cUk/NbPPSGqWdEfs/Cck3WNmdyp61+JvJR30OjwApBnGbCQV5kAjrcTm0y11zrX4nQUAcHqM2UhUTOEAAAAAxoA70AAAAMAYcAcaAAAAGAMKNAAAADAGFGgAAABgDCjQAAAAwBhQoAEAAIAxoEADAAAAY/D/A/oVpR6PcmiGAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 0s - loss: 1.3688 - accuracy: 0.6977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6976847648620605"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "model_2 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.Flatten(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "earlystop_callback = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_accuracy', \n",
    "  patience=5)\n",
    "model_2.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_2.fit(train_data, train_labels, callbacks=[earlystop_callback], validation_data = (train_data, train_labels), validation_split=0.2, epochs=20, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_acc = model_2.evaluate(test_data,  test_labels, verbose=2)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUQp1GfUDnhP"
   },
   "source": [
    "### Global Average Pooling Layer\n",
    "\n",
    "Create `model_3` that replaces the `Flatten` layer with `GlobalAveragePooling1D()` layer. Fit the model, plot the learning curves, and report the accuracy on the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "-6oOEP67AJk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 2.8636 - accuracy: 0.3471 - val_loss: 2.3036 - val_accuracy: 0.3450\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 2.2595 - accuracy: 0.3550 - val_loss: 2.1835 - val_accuracy: 0.3500\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.0842 - accuracy: 0.3808 - val_loss: 1.9579 - val_accuracy: 0.4001\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.8600 - accuracy: 0.4791 - val_loss: 1.7669 - val_accuracy: 0.4992\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.6900 - accuracy: 0.5591 - val_loss: 1.6389 - val_accuracy: 0.5799\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.5512 - accuracy: 0.6102 - val_loss: 1.5421 - val_accuracy: 0.6160\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.4313 - accuracy: 0.6466 - val_loss: 1.4691 - val_accuracy: 0.6455\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.3176 - accuracy: 0.6770 - val_loss: 1.4125 - val_accuracy: 0.6694\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 1.2126 - accuracy: 0.7022 - val_loss: 1.3503 - val_accuracy: 0.6772\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.0930 - accuracy: 0.7285 - val_loss: 1.2833 - val_accuracy: 0.7023\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.9842 - accuracy: 0.7602 - val_loss: 1.2217 - val_accuracy: 0.7245\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.8854 - accuracy: 0.7873 - val_loss: 1.1881 - val_accuracy: 0.7329\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.8002 - accuracy: 0.8085 - val_loss: 1.1717 - val_accuracy: 0.7362\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.7320 - accuracy: 0.8205 - val_loss: 1.1517 - val_accuracy: 0.7462\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.6728 - accuracy: 0.8298 - val_loss: 1.1459 - val_accuracy: 0.7490\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.6210 - accuracy: 0.8402 - val_loss: 1.1559 - val_accuracy: 0.7446\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5735 - accuracy: 0.8534 - val_loss: 1.1607 - val_accuracy: 0.7457\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.5306 - accuracy: 0.8647 - val_loss: 1.1590 - val_accuracy: 0.7568\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.4924 - accuracy: 0.8760 - val_loss: 1.1781 - val_accuracy: 0.7551\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4576 - accuracy: 0.8820 - val_loss: 1.1847 - val_accuracy: 0.7585\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 - 0s - loss: 1.2572 - accuracy: 0.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7422083616256714"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "model_3 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "earlystop_callback = keras.callbacks.EarlyStopping(\n",
    "  monitor='val_accuracy', \n",
    "  patience=5)\n",
    "model_3.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_3.fit(train_data, train_labels, callbacks=[earlystop_callback], validation_data = (train_data, train_labels), validation_split=0.2, epochs=20, batch_size=128)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_acc = model_3.evaluate(test_data,  test_labels, verbose=2)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whyOiaTrEhPc"
   },
   "source": [
    "### Different Learning Rates\n",
    "\n",
    "Train `model_4`, `model_5`, and `model_6` using Adam optimizer with learning rates of 0.01, 0.001, and 0.0001, and discuss the impact on the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Drknr85sOsEq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 21ms/step - loss: 2.1298 - accuracy: 0.4420 - val_loss: 1.6052 - val_accuracy: 0.6027\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.3746 - accuracy: 0.6611 - val_loss: 1.2227 - val_accuracy: 0.6973\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 17ms/step - loss: 0.9287 - accuracy: 0.7614 - val_loss: 1.1391 - val_accuracy: 0.7435\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.6489 - accuracy: 0.8315 - val_loss: 1.1585 - val_accuracy: 0.7485\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.4722 - accuracy: 0.8767 - val_loss: 1.1502 - val_accuracy: 0.7707\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3673 - accuracy: 0.9058 - val_loss: 1.2976 - val_accuracy: 0.7507\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2805 - accuracy: 0.9285 - val_loss: 1.3054 - val_accuracy: 0.7585\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2537 - accuracy: 0.9358 - val_loss: 1.4876 - val_accuracy: 0.7529\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.2092 - accuracy: 0.9442 - val_loss: 1.3982 - val_accuracy: 0.7735\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1715 - accuracy: 0.9545 - val_loss: 1.5254 - val_accuracy: 0.7746\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.7742 - accuracy: 0.3095 - val_loss: 3.6959 - val_accuracy: 0.3450\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.5489 - accuracy: 0.3534 - val_loss: 3.3297 - val_accuracy: 0.3450\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 3.0333 - accuracy: 0.3532 - val_loss: 2.6892 - val_accuracy: 0.3450\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 2.5023 - accuracy: 0.3534 - val_loss: 2.3693 - val_accuracy: 0.3450\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 2.3556 - accuracy: 0.3534 - val_loss: 2.3322 - val_accuracy: 0.3450\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.3320 - accuracy: 0.3534 - val_loss: 2.3175 - val_accuracy: 0.3450\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.3203 - accuracy: 0.3534 - val_loss: 2.3051 - val_accuracy: 0.3450\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.3057 - accuracy: 0.3532 - val_loss: 2.2944 - val_accuracy: 0.3450\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 2.2968 - accuracy: 0.3539 - val_loss: 2.2842 - val_accuracy: 0.3450\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 2.2833 - accuracy: 0.3538 - val_loss: 2.2728 - val_accuracy: 0.3450\n",
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.8251 - accuracy: 0.0458 - val_loss: 3.8192 - val_accuracy: 0.1180\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 3.8138 - accuracy: 0.2487 - val_loss: 3.8078 - val_accuracy: 0.3511\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.8020 - accuracy: 0.3438 - val_loss: 3.7959 - val_accuracy: 0.3472\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.7896 - accuracy: 0.3542 - val_loss: 3.7828 - val_accuracy: 0.3461\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.7760 - accuracy: 0.3567 - val_loss: 3.7683 - val_accuracy: 0.3450\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.7609 - accuracy: 0.3577 - val_loss: 3.7522 - val_accuracy: 0.3450\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 3.7438 - accuracy: 0.3557 - val_loss: 3.7339 - val_accuracy: 0.3450\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.7247 - accuracy: 0.3552 - val_loss: 3.7130 - val_accuracy: 0.3450\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.7021 - accuracy: 0.3546 - val_loss: 3.6889 - val_accuracy: 0.3450\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 3.6765 - accuracy: 0.3539 - val_loss: 3.6616 - val_accuracy: 0.3450\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "model_4 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_4.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_4.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=10, batch_size=128)\n",
    "\n",
    "model_5 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_5.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_5.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=10, batch_size=128)\n",
    "\n",
    "\n",
    "model_6 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_6.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_6.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_ykG1fbPr8t"
   },
   "source": [
    "### Reduce Learning Rate on Plateau\n",
    "\n",
    "Apply ReduceLROnPlatau callback and report the performance. If needed, check Lecture 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "zKlcGZRKA8h9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 2.1353 - accuracy: 0.4412 - val_loss: 1.6700 - val_accuracy: 0.6027\n",
      "Epoch 2/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.4114 - accuracy: 0.6509 - val_loss: 1.2581 - val_accuracy: 0.7012\n",
      "Epoch 3/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.9601 - accuracy: 0.7609 - val_loss: 1.1838 - val_accuracy: 0.7201\n",
      "Epoch 4/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.6772 - accuracy: 0.8252 - val_loss: 1.1570 - val_accuracy: 0.7446\n",
      "Epoch 5/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5023 - accuracy: 0.8662 - val_loss: 1.1729 - val_accuracy: 0.7657\n",
      "Epoch 6/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3806 - accuracy: 0.8990 - val_loss: 1.2475 - val_accuracy: 0.7685\n",
      "Epoch 7/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2845 - accuracy: 0.9269 - val_loss: 1.2618 - val_accuracy: 0.7546\n",
      "Epoch 8/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2326 - accuracy: 0.9371 - val_loss: 1.3070 - val_accuracy: 0.7752\n",
      "Epoch 9/10\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.1832 - accuracy: 0.9500 - val_loss: 1.4421 - val_accuracy: 0.7752\n",
      "Epoch 10/10\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1731 - accuracy: 0.9527 - val_loss: 1.3583 - val_accuracy: 0.7780\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-6, verbose=1)]\n",
    "model_7 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_7.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_7.fit(train_data, train_labels, callbacks=callbacks, validation_data = (train_data, train_labels), validation_split=0.2, epochs=10, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgYEyznRQBNv"
   },
   "source": [
    "### Learning Rate Scheduler\n",
    "\n",
    "Apply a Step Decay Learning Rate Scheduler, to reduce the learning rate by half every 5 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "oB50cq4DoXGO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 1s 18ms/step - loss: 2.4042 - accuracy: 0.3517 - val_loss: 1.9155 - val_accuracy: 0.3817\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 1.7262 - accuracy: 0.5410 - val_loss: 1.5528 - val_accuracy: 0.6132\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 1.3154 - accuracy: 0.6786 - val_loss: 1.2680 - val_accuracy: 0.7051\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.9479 - accuracy: 0.7653 - val_loss: 1.1481 - val_accuracy: 0.7362\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.6977 - accuracy: 0.8248 - val_loss: 1.1150 - val_accuracy: 0.7613\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.5247 - accuracy: 0.8617 - val_loss: 1.1165 - val_accuracy: 0.7668\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.4470 - accuracy: 0.8831 - val_loss: 1.1522 - val_accuracy: 0.7679\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3841 - accuracy: 0.8985 - val_loss: 1.1759 - val_accuracy: 0.7718\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.3433 - accuracy: 0.9120 - val_loss: 1.2062 - val_accuracy: 0.7691\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2950 - accuracy: 0.9255 - val_loss: 1.2466 - val_accuracy: 0.7752\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.2431 - accuracy: 0.9385 - val_loss: 1.2415 - val_accuracy: 0.7802\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2241 - accuracy: 0.9422 - val_loss: 1.2591 - val_accuracy: 0.7796\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2117 - accuracy: 0.9456 - val_loss: 1.2909 - val_accuracy: 0.7752\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.2001 - accuracy: 0.9452 - val_loss: 1.3034 - val_accuracy: 0.7807\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1828 - accuracy: 0.9510 - val_loss: 1.3194 - val_accuracy: 0.7802\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1642 - accuracy: 0.9556 - val_loss: 1.3349 - val_accuracy: 0.7802\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 1s 16ms/step - loss: 0.1585 - accuracy: 0.9585 - val_loss: 1.3477 - val_accuracy: 0.7796\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1605 - accuracy: 0.9546 - val_loss: 1.3773 - val_accuracy: 0.7763\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 1s 14ms/step - loss: 0.1494 - accuracy: 0.9594 - val_loss: 1.3719 - val_accuracy: 0.7769\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 1s 15ms/step - loss: 0.1434 - accuracy: 0.9592 - val_loss: 1.3819 - val_accuracy: 0.7785\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    if epoch % 5 == 0:\n",
    "        return lr / 2\n",
    "    else:\n",
    "        return lr\n",
    "callbacks = [LearningRateScheduler(lr_time_based_decay, verbose=0)]\n",
    "model_8 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.GlobalAveragePooling1D(),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_8.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_8.fit(train_data, train_labels, callbacks=callbacks, validation_data = (train_data, train_labels), validation_split=0.2, epochs=20, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8IoQ-h6Syyj"
   },
   "source": [
    "\n",
    "Feel free to perform additional hyperparameter tuning if you wish, but it is not required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1ZYPE7-BjTe"
   },
   "source": [
    "## 4. Create and Train a Model with Recurrent Layers\n",
    "\n",
    "Next, create `model_9` using LSTM layers similar to the model in Lecture 18. Train the model for 5 epochs and report the performance. Expect longer training time with RNN models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "JpZc6ZuB_3b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 5s 54ms/step - loss: 2.5535 - accuracy: 0.3840 - val_loss: 2.0204 - val_accuracy: 0.4908\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 1.8279 - accuracy: 0.5333 - val_loss: 1.7343 - val_accuracy: 0.5543\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 1.5625 - accuracy: 0.5893 - val_loss: 1.5965 - val_accuracy: 0.5943\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 1.3955 - accuracy: 0.6283 - val_loss: 1.5637 - val_accuracy: 0.5927\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 1.2112 - accuracy: 0.6665 - val_loss: 1.6141 - val_accuracy: 0.6105\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here()\n",
    "model_9 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_9.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model_9.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=5, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh84hp-iSOqI"
   },
   "source": [
    "### Improved Model\n",
    "\n",
    "Use the strategy that was the most successful with the above models with Dense layers (e.g., LR scheduler or ReduceLROnPlateau), and train an LSTM model using that strategy.\n",
    "\n",
    "Feel free to perform additional hyperparameter tuning if you wish, but it is not required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "FTvAJ3aqABr8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "57/57 [==============================] - 5s 56ms/step - loss: 2.3108 - accuracy: 0.4168 - val_loss: 2.3838 - val_accuracy: 0.2554\n",
      "Epoch 2/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 2.0251 - accuracy: 0.4441 - val_loss: 2.3203 - val_accuracy: 0.4591\n",
      "Epoch 3/20\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 1.6555 - accuracy: 0.5589 - val_loss: 1.7291 - val_accuracy: 0.5559\n",
      "Epoch 4/20\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 1.3873 - accuracy: 0.6225 - val_loss: 1.7166 - val_accuracy: 0.5737\n",
      "Epoch 5/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 1.1185 - accuracy: 0.6951 - val_loss: 1.7170 - val_accuracy: 0.5999\n",
      "Epoch 6/20\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 0.8230 - accuracy: 0.7698 - val_loss: 1.7772 - val_accuracy: 0.5993\n",
      "Epoch 7/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.6600 - accuracy: 0.8173 - val_loss: 1.9630 - val_accuracy: 0.5915\n",
      "Epoch 8/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.5286 - accuracy: 0.8561 - val_loss: 2.1174 - val_accuracy: 0.6010\n",
      "Epoch 9/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.4357 - accuracy: 0.8768 - val_loss: 2.3309 - val_accuracy: 0.5921\n",
      "Epoch 10/20\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 0.3795 - accuracy: 0.8953 - val_loss: 2.3726 - val_accuracy: 0.5893\n",
      "Epoch 11/20\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.2854 - accuracy: 0.9191 - val_loss: 2.4931 - val_accuracy: 0.6194\n",
      "Epoch 12/20\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.2435 - accuracy: 0.9307 - val_loss: 2.6505 - val_accuracy: 0.6055\n",
      "Epoch 13/20\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.2034 - accuracy: 0.9417 - val_loss: 2.7817 - val_accuracy: 0.6093\n",
      "Epoch 14/20\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.1850 - accuracy: 0.9479 - val_loss: 2.8696 - val_accuracy: 0.6010\n",
      "Epoch 15/20\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 0.1885 - accuracy: 0.9450 - val_loss: 2.8907 - val_accuracy: 0.6027\n",
      "Epoch 16/20\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.1468 - accuracy: 0.9555 - val_loss: 3.0007 - val_accuracy: 0.6155\n",
      "Epoch 17/20\n",
      "57/57 [==============================] - 3s 50ms/step - loss: 0.1281 - accuracy: 0.9585 - val_loss: 3.0388 - val_accuracy: 0.6066\n",
      "Epoch 18/20\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.1249 - accuracy: 0.9601 - val_loss: 3.0924 - val_accuracy: 0.6010\n",
      "Epoch 19/20\n",
      "57/57 [==============================] - 3s 51ms/step - loss: 0.1171 - accuracy: 0.9633 - val_loss: 3.2154 - val_accuracy: 0.6082\n",
      "Epoch 20/20\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 0.1119 - accuracy: 0.9631 - val_loss: 3.2458 - val_accuracy: 0.6088\n"
     ]
    }
   ],
   "source": [
    "# Your Code Here\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    if epoch % 5 == 0:\n",
    "        return lr / 2\n",
    "    else:\n",
    "        return lr\n",
    "callbacks = [LearningRateScheduler(lr_time_based_decay, verbose=0)]\n",
    "model_9 = tf.keras.Sequential([\n",
    "       tf.keras.layers.Embedding(input_dim=max_features, output_dim=64, input_length=300),\n",
    "       tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "       tf.keras.layers.Dense(1024, activation='relu'),\n",
    "       tf.keras.layers.Dropout(0.5),\n",
    "       tf.keras.layers.Dense(46, activation='softmax')\n",
    "])\n",
    "model_9.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "history = model_9.fit(train_data, train_labels, callbacks=callbacks, validation_data = (train_data, train_labels), validation_split=0.2, epochs=20, batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1LfCvrgrvYA"
   },
   "source": [
    "## 5. Create and Train a Transformer Model\n",
    "\n",
    "Create `model_10` that will implement a Transformer Network. Follow the instructions in Lecture 19. Train the transformer model from scratch, it is not required to use a pretrained model. Select the hyperparameters as you wish, but aim to obtain over 70% accuracy.\n",
    "\n",
    "Feel free to perform additional hyperparameter tuning if you wish, but it is not required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "onp8ED-Arl-4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 4s 52ms/step - loss: 2.7946 - accuracy: 0.3331 - val_loss: 2.0508 - val_accuracy: 0.4969\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 1.9015 - accuracy: 0.5509 - val_loss: 1.6373 - val_accuracy: 0.5854\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 3s 45ms/step - loss: 1.4868 - accuracy: 0.6458 - val_loss: 1.4686 - val_accuracy: 0.6377\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 3s 48ms/step - loss: 1.1908 - accuracy: 0.7151 - val_loss: 1.2360 - val_accuracy: 0.7117\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 3s 49ms/step - loss: 0.9268 - accuracy: 0.7752 - val_loss: 1.0867 - val_accuracy: 0.7574\n",
      "71/71 - 0s - loss: 1.2572 - accuracy: 0.7422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7422083616256714"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your Code Here\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.token_embeddings = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.positional_embeddings = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.positional_embeddings(positions)\n",
    "        input_embeddings = self.token_embeddings(inputs)\n",
    "        return input_embeddings + position_embeddings\n",
    "    \n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.feed_forward_net = keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layer_normalization1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_normalization2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        multi_head_att_output = self.multi_head_attention(inputs, inputs)\n",
    "        multi_head_att_dropout = self.dropout1(multi_head_att_output, training=training)\n",
    "        add_norm_output_1 = self.layer_normalization1(inputs + multi_head_att_dropout)\n",
    "        feed_forward_output = self.feed_forward_net(add_norm_output_1)\n",
    "        feed_forward_dropout = self.dropout2(feed_forward_output, training=training)\n",
    "        add_norm_output_2 = self.layer_normalization2(add_norm_output_1 + feed_forward_dropout)\n",
    "        return add_norm_output_2\n",
    "maxlen = 300 \n",
    "embed_dim = 64\n",
    "num_heads = 2  \n",
    "ff_dim = 1024\n",
    "vocab_size = 30000  \n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, num_heads, ff_dim)(embedding_layer)\n",
    "\n",
    "# classifier\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(46, activation=\"softmax\")(x)\n",
    "\n",
    "model_10 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model_10.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model_10.fit(train_data, train_labels, validation_data = (train_data, train_labels), validation_split=0.2, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = model_3.evaluate(test_data,  test_labels, verbose=2)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPg2wa3B7TsOpBGbe62yE+k",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
